{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandas.tseries.offsets import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import grid_search\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = {}\n",
    "path['train'] = {'order':'./training_data_2/order_data/order_data_{}', \n",
    "                    'weather': './training_data_2/weather_data/weather_data_{}',\n",
    "                    'traffic': './training_data_2/traffic_data/traffic_data_{}',\n",
    "                    'district':'./training_data_2/cluster_map/cluster_map',\n",
    "                    'poi':'./training_data_2/poi_data/poi_data'}\n",
    "path['test'] = {'order':'./test_data_2/order_data/order_data_{}_test', \n",
    "                'weather': './test_data_2/weather_data/weather_data_{}_test',\n",
    "                'traffic': './test_data_2/traffic_data/traffic_data_{}_test',\n",
    "                'district':'./test_data_2/cluster_map/cluster_map'}\n",
    "\n",
    "M = np.timedelta64(1, 'm') # base time stamp of 1 minute\n",
    "\n",
    "test_slot1 = range(46,154,12) # The test slot for day 22, 26, 30\n",
    "test_slot2 = range(58,154,12) # The test slot for day 24, 28\n",
    "\n",
    "D_range = range(1,67) # List of all district Ids\n",
    "T_range = range(1,145) # List of all time slots\n",
    "\n",
    "# Dictionary of District Info Table\n",
    "district_dict = pd.read_table(path['train']['district'], header=None, index_col=0)\n",
    "district_dict = district_dict[1].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print len(district_dict) == 66"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Funtion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def index(district, slot):\n",
    "    if type(district) is int:\n",
    "        if type(slot) is int:\n",
    "            return [x for x in itertools.product([district],[slot])]\n",
    "        else:\n",
    "            return [x for x in itertools.product([district],slot)]\n",
    "    else:\n",
    "        if type(slot) is int:\n",
    "            return [x for x in itertools.product(district,[slot])]\n",
    "        else:\n",
    "            return [x for x in itertools.product(district,slot)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def District(df):\n",
    "    return df['district'].apply(lambda x: district_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Weekday(df):\n",
    "    return pd.to_datetime(df['time']).apply(lambda x: x.weekday())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Time(df, day):\n",
    "    time = pd.to_datetime(df['time'])\n",
    "    time = (time - pd.Timestamp(day)) / M / 10 + 1\n",
    "    return time.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting testing data and training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Traffic(day, option):\n",
    "    df = pd.read_table(path[option]['traffic'].format(day.date()), header=None,\n",
    "                      names=['district', 'LV1', 'LV2', 'LV3', 'LV4','time'])\n",
    "    df['district'] = District(df)\n",
    "    df['weekday'] = Weekday(df)\n",
    "    df['time'] = Time(df, str(day.date()))\n",
    "    for L in ['LV{}'.format(n) for n in range(1,5)]:\n",
    "        df[L]=df[L].apply(lambda x: x.split(':')[1]).astype(int)\n",
    "    index = pd.MultiIndex.from_arrays([df['district'].values, df['time'].values], names=('district', 'time'))\n",
    "    return pd.DataFrame({'weekday':df['weekday'].values,\n",
    "                         'day':day.day,\n",
    "                         'district':df['district'].values,\n",
    "                         'time':df['time'].values,\n",
    "                         'LV1':df['LV1'].values, \n",
    "                         'LV2':df['LV2'].values,\n",
    "                         'LV3':df['LV3'].values,\n",
    "                         'LV4':df['LV4'].values,}, index=index).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DTG: District Time Gap\n",
    "def DTG(day, option):\n",
    "    df = pd.read_table(path[option]['order'].format(day.date()), header=None, usecols=[1,3,6],\n",
    "                      names=['driver', 'district', 'time'])\n",
    "    df = df[df['driver'].isnull()] \n",
    "    df['district'] = District(df)\n",
    "    df['time'] = Time(df, day.date())\n",
    "    Order = df.groupby(['district', 'time'])\n",
    "    return pd.DataFrame({'gap':Order.size()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Weather(day, option):\n",
    "    df = pd.read_table(path[option]['weather'].format(day.date()), header=None,\n",
    "                      names=['time', 'weather', 'temprature', 'pm2.5'])\n",
    "    df['time'] = Time(df, day.date())\n",
    "    df = df.drop_duplicates(subset='time')\n",
    "    DF = pd.DataFrame({'time': T_range}, columns=df.columns)\n",
    "    DF = DF.set_index('time')\n",
    "    DF.update(df.set_index('time'))\n",
    "    return DF.fillna(method='bfill').fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Dictionary of order data for testing, indexed by date, cols = [gap]\n",
    "test_order = {} \n",
    "# Dictionary of traffic data for testing, indexed by date, cols = [weekday, district, time, LV1, LV2, LV3, LV4]\n",
    "test_traffic = {}\n",
    "# Dictionary of weather data for testing, indexed by date, cols = [temperature, weather, pm2.5]\n",
    "test_weather = {} \n",
    "for day in pd.date_range('1/23/2016', periods=5, freq='2D'):\n",
    "    test_order[str(day.date())] = DTG(day, 'test')\n",
    "    test_traffic[str(day.date())] = Traffic(day, 'test')\n",
    "    test_weather[str(day.date())] = Weather(day, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Check data\n",
    "print len(test_order.keys()) == 5\n",
    "print len(test_traffic.keys()) == 5\n",
    "print len(test_weather.keys()) == 5\n",
    "print all(test_order['2016-01-23'].columns.values == np.array(['gap']))\n",
    "print all(test_traffic['2016-01-23'].columns.values == np.array(['LV1', 'LV2', 'LV3', 'LV4', 'day', 'district', 'time', 'weekday']))\n",
    "print all(test_weather['2016-01-23'].columns.values == np.array(['weather', 'temprature', 'pm2.5']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Dictionary of order data for training, indexed by date, cols = [gap]\n",
    "train_order = {}\n",
    "# Dictionary of traffic data for training, indexed by date, cols = [weekday, district, time, LV1, LV2, LV3, LV4]\n",
    "train_traffic = {}\n",
    "# Dictionary of weather data for training, indexed by date, cols = [temperature, weather, pm2.5]\n",
    "train_weather = {}\n",
    "for day in pd.date_range('1/1/2016', periods=21, freq='D'):\n",
    "    train_order[str(day.date())] = DTG(day, 'train')\n",
    "    train_traffic[str(day.date())] = Traffic(day, 'train')\n",
    "    train_weather[str(day.date())] = Weather(day, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Check data\n",
    "print len(train_order.keys()) == 21\n",
    "print len(train_traffic.keys()) == 21\n",
    "print len(train_weather.keys()) == 21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columns = ['district'] + range(1,26)\n",
    "POI = pd.DataFrame(columns=columns)\n",
    "with open(path['train']['poi'], 'r') as f:\n",
    "    for i, line in enumerate(f): \n",
    "        interests = line.strip().split('\\t')\n",
    "        row = {'district': interests[0]}\n",
    "        for item in interests[1:]:\n",
    "            category,num = item.split(':')\n",
    "            category = int(category.split('#')[0])\n",
    "            if category in row:\n",
    "                row[category] += int(num)\n",
    "            else:\n",
    "                row[category] = int(num)\n",
    "        POI = pd.concat( [POI, pd.DataFrame(row, index=[i], columns=columns)])\n",
    "POI['district'] = District(POI)\n",
    "POI = POI.set_index('district').sort_index()\n",
    "POI = POI.fillna(0)\n",
    "# Standardization\n",
    "POI = (POI - POI.mean()) / POI.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing training data X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocessing(day):\n",
    "    X = train_order[day].reindex(index(D_range,T_range)).fillna(0)\n",
    "    X['last'] = X['gap'].shift().fillna(method='bfill')\n",
    "    X['diff'] = pd.Series(index=X.index)\n",
    "    X['GAP'] = pd.Series(index=X.index)\n",
    "    for D in D_range:\n",
    "        X.loc[(D, T_range),'diff'] = X.loc[(D, T_range),'gap'].diff().shift(-1).fillna(0)\n",
    "        X.loc[(D, T_range), 'GAP'] = X.loc[(D, T_range),'gap'].shift(-1).fillna(method='ffill')\n",
    "    # filling nearest value for missin traffic data \n",
    "    tempX = train_traffic[day].reindex(index(D_range,T_range)).fillna(method='bfill').fillna(method='ffill')\n",
    "    X = pd.concat([X, tempX],axis=1)\n",
    "    X = X.join(train_weather[day], on='time')\n",
    "    Y_diff = X['diff']\n",
    "    Y_gap = X['GAP']\n",
    "    X.drop('diff', axis=1, inplace=True)\n",
    "    X.drop('GAP', axis=1, inplace=True)\n",
    "    return X, Y_diff, Y_gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create X, Y_diff, Y_gap\n",
    "# X = []\n",
    "# Y_diff = []\n",
    "# Y_gap = []\n",
    "# for d in pd.date_range('1/2/2016', periods=20, freq='D'):\n",
    "#     tempX, tempY_diff, tempY_gap = preprocessing(str(d.date()))\n",
    "#     X.append(tempX)\n",
    "#     Y_diff.append(tempY_diff)\n",
    "#     Y_gap.append(tempY_gap)\n",
    "# X = pd.concat(X)\n",
    "# X = X.join(POI,on='district')\n",
    "# X.sort_index(inplace=True)\n",
    "# Y_diff = pd.concat(Y_diff)\n",
    "# Y_diff.sort_index(inplace=True)\n",
    "# Y_gap = pd.concat(Y_gap)\n",
    "# Y_gap.sort_index(inplace=True)\n",
    "# X.to_csv('./X.csv', columns=X.columns, header=True)\n",
    "# Y_diff.to_csv('./Y_diff.csv', header=True)\n",
    "# Y_gap.to_csv('./Y_gap.csv', header=True)\n",
    "\n",
    "X = pd.read_csv('./X.csv', index_col=('district', 'time'))\n",
    "Y_gap = pd.read_csv('./Y_gap.csv', index_col=('district', 'time'))\n",
    "Y_diff = pd.read_csv('./Y_diff.csv', index_col=('district', 'time'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print len(X.columns) == 38\n",
    "print Y_diff.shape[0] == X.shape[0]\n",
    "print Y_gap.shape[0] == X.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Developing Zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def add_test_data(day):\n",
    "    X = train_order[day]\n",
    "    X['diff'] = pd.Series(index=X.index)\n",
    "    for D in D_range:\n",
    "        X.loc[(D, T_range),'diff'] = X.loc[(D, T_range),'gap'].diff().shift(-1).fillna(0)\n",
    "    # filling nearest value for missin traffic data \n",
    "    tempX = train_traffic[day].reindex(index(D_range,T_range)).fillna(method='bfill').fillna(method='ffill')\n",
    "    X = pd.concat([X, tempX],axis=1)\n",
    "    X = X.join(train_weather[day], on='time')\n",
    "    Y = X['diff']\n",
    "    X.drop('diff', axis=1, inplace=True)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identified the most common gap growth each day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    1   2   3   4   5   6   7   8   9   10  11\n",
      "2    0  -1   1   2  -2   3  -3  -4   4   5  -5\n",
      "3    0   1  -1   2  -2  -3   3   4  -4   5  -5\n",
      "4    0   1  -1  -2   2  -3   3   4  -4   5  -5\n",
      "5    0  -1   1   2  -2   3  -3   4  -4  -5   5\n",
      "6    0   1  -1   2  -2   3  -3  -4   4   5  -5\n",
      "7    0  -1   1  -2   2   3  -3  -4   4   5  -5\n",
      "8    0  -1   1  -2   2   3  -3  -4   4   5  -5\n",
      "9    0   1  -1  -2   2   3  -3   4  -4  -5   5\n",
      "10   0   1  -1  -2   2   3  -3   4  -4  -5   5\n",
      "11   0   1  -1   2  -2   3  -3  -4   4   5  -5\n",
      "12   0   1  -1  -2   2  -3   3   4  -4   5  -5\n",
      "13   0   1  -1  -2   2  -3   3   4  -4  -5   5\n",
      "14   0  -1   1   2  -2   3  -3   4  -4   5  -5\n",
      "15   0   1  -1  -2   2  -3   3  -4   4  -5   5\n",
      "16   0   1  -1  -2   2  -3   3   4  -4  -5   5\n",
      "17   0  -1   1   2  -2  -3   3   4  -4  -5   5\n",
      "18   0  -1   1  -2   2   3  -3  -4   4   5  -5\n",
      "19   0  -1   1   2  -2   3  -3   4  -4   5  -5\n",
      "20   0  -1   1  -2   2   3  -3   4  -4  -5   5\n",
      "21   0   1  -1  -2   2   3  -3  -4   4  -5   5\n"
     ]
    }
   ],
   "source": [
    "DF = pd.DataFrame(columns=range(1,12))\n",
    "for d in pd.date_range('1/2/2016', periods=20, freq='1D'):\n",
    "    df = train_order[str(d.date())]\n",
    "    df = df.reindex(index(D_range, T_range)).fillna(0)\n",
    "    for D in D_range:\n",
    "        df.loc[(D, T_range),'diff'] = df.loc[(D, T_range),'gap'].diff().shift(-1).fillna(0)\n",
    "    row = pd.DataFrame(df['diff'].value_counts().sort_values(ascending=False).iloc[:11].index.values.reshape((1,11)),\n",
    "                       columns=range(1,12), index=[d.day])\n",
    "    DF = DF.append(row)\n",
    "print DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identified the most common gap each day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DF = pd.DataFrame(columns=range(1,12))\n",
    "for d in pd.date_range('1/2/2016', periods=20, freq='1D'):\n",
    "    df = train_order[str(d.date())]\n",
    "    row = pd.DataFrame(df['gap'].value_counts().sort_values(ascending=False)[:11].index.values.reshape((1,11)),\n",
    "                       columns=range(1,12), index=[d.day])\n",
    "    DF = DF.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for d in pd.date_range('1/23/2016', periods=5, freq='2D'):\n",
    "    df = test_order[str(d.date())]\n",
    "    row = pd.DataFrame(df['gap'].value_counts().sort_values(ascending=False)[:11].index.values.reshape((1,11)),\n",
    "                       columns=range(1,12), index=[d.day])\n",
    "    DF = DF.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    1   2   3   4   5   6   7   8   9   10  11\n",
      "2    1   2   3   4   5   6   7   8   9  10  11\n",
      "3    1   2   3   4   5   6   7   8  10   9  11\n",
      "4    1   2   3   4   5   6   7   9   8  10  11\n",
      "5    1   2   3   4   5   6   7   8   9  10  11\n",
      "6    1   2   3   4   5   6   7   8   9  10  12\n",
      "7    1   2   3   4   5   6   7   8   9  10  11\n",
      "8    1   2   3   4   5   6   7   8   9  10  12\n",
      "9    1   2   3   4   5   6   7   8   9  10  11\n",
      "10   1   2   3   4   5   6   7   8   9  10  11\n",
      "11   1   2   3   4   5   6   7   8   9  10  11\n",
      "12   1   2   3   4   5   6   7   8   9  11  10\n",
      "13   1   2   3   4   5   6   7   8   9  11  10\n",
      "14   1   2   3   4   5   6   7   8   9  10  11\n",
      "15   1   2   3   4   5   6   7   8   9  10  11\n",
      "16   1   2   3   4   5   6   7   8   9  10  11\n",
      "17   1   2   3   4   5   6   7   8   9  10  11\n",
      "18   1   2   3   4   5   6   7   8   9  11  10\n",
      "19   1   2   3   4   5   6   7   8   9  12  11\n",
      "20   1   2   3   4   5   6   7   8   9  10  11\n",
      "21   1   2   3   4   5   6   7   8   9  10  11\n",
      "23   1   2   3   4   5   6   7   8   9  10  11\n",
      "25   1   2   3   4   5   7   6   9  10   8  12\n",
      "27   1   2   3   4   5   6   7  10  11   8  13\n",
      "29   1   2   3   4   7   5   8   6  10   9  15\n",
      "31   1   2   3   4   5   6   8   7   9  10  14\n"
     ]
    }
   ],
   "source": [
    "# columns is the top 11 most common gap\n",
    "# index is each day\n",
    "print DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method4 by GradientBoosting on classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def score3(day, pred):\n",
    "    ans = test_order[day].reindex(index(D_range, S_range[day])).fillna(0)\n",
    "    ans = ans['gap'].values\n",
    "    pred = pred[ans>0]\n",
    "    ans = ans[ans>0]\n",
    "    gap = (ans - pred) / ans\n",
    "    return np.fabs(gap).sum()/ans.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def select_last_points(day, slot):\n",
    "    slot = np.array(slot)\n",
    "    x = test_order[day].reindex(index(D_range, slot)).fillna(0)\n",
    "    x['last'] = test_order[day].reindex(index(D_range, slot-1)).fillna(0)\n",
    "    x = pd.concat([x, test_traffic[day]],axis=1)\n",
    "    x = x.drop(x[x['gap'].isnull()].index)\n",
    "    # For missing traffic data on district 54, replaced by district 17 \n",
    "    for t in slot:\n",
    "        x.loc[(54,t)]['LV1':'weekday'] = x.loc[(17,t)]['LV1':'weekday']\n",
    "    x = x.join(test_weather[day], on='time')\n",
    "    x = x.join(POI,on='district')\n",
    "    print \"Select data from {} on {}\".format(day, slot)\n",
    "    print \"\\t shape: {}\".format(x.shape)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "slot1 = range(45,153,12) # Last time slot of test slot for day 23, 27, 31\n",
    "slot2 = range(57,153,12) # Last time slot of test slot for day 25, 29\n",
    "S_range = {'2016-01-23':slot1, '2016-01-25':slot2, '2016-01-27':slot1, '2016-01-29':slot2, '2016-01-31':slot1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
       "              max_depth=3, max_features=0.8, max_leaf_nodes=None,\n",
       "              min_samples_leaf=10, min_samples_split=20,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=50,\n",
       "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'loss': 'deviance', 'learning_rate': 0.1, 'n_estimators': 50, 'min_samples_leaf':10, 'min_samples_split':100,\n",
    "          'max_depth': 3, 'max_features': 0.8, 'subsample': 1.0, 'min_samples_split': 20}\n",
    "clf = GradientBoostingClassifier(**params)\n",
    "clf.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select data from 2016-01-31 on [ 44  56  68  80  92 104 116 128 140]\n",
      "\t shape: (594, 38)\n",
      "\t score: 0.487475705874\n",
      "Select data from 2016-01-23 on [ 44  56  68  80  92 104 116 128 140]\n",
      "\t shape: (594, 38)\n",
      "\t score: 0.455771252706\n",
      "Select data from 2016-01-29 on [ 56  68  80  92 104 116 128 140]\n",
      "\t shape: (528, 38)\n",
      "\t score: 0.5231750185\n",
      "Select data from 2016-01-27 on [ 44  56  68  80  92 104 116 128 140]\n",
      "\t shape: (594, 38)\n",
      "\t score: 0.486871117277\n",
      "Select data from 2016-01-25 on [ 56  68  80  92 104 116 128 140]\n",
      "\t shape: (528, 38)\n",
      "\t score: 0.527273014907\n",
      "0.494759231394\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "SLOT1 = range(44,152,12)\n",
    "SLOT2 = range(56,152,12)\n",
    "RANGE = {'2016-01-23': SLOT1, '2016-01-25': SLOT2, '2016-01-27': SLOT1, '2016-01-29': SLOT2, '2016-01-31': SLOT1}\n",
    "scores = []\n",
    "for day in RANGE.keys():\n",
    "    x = select_last_points(day, RANGE[day])\n",
    "    score = score3(day, clf.predict(x[columns]))\n",
    "    scores.append(score * x.shape[0])\n",
    "    print '\\t score: {}'.format(score)\n",
    "print np.array(scores).sum()/2838"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columns = []\n",
    "for i, important in enumerate(clf.feature_importances_ > 0.03):\n",
    "    if important:\n",
    "        columns.append(X.columns[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "newY = Y_gap[Y_gap>0]\n",
    "newX = X[Y_gap>0]\n",
    "newY[newY>12]=13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
       "              max_depth=3, max_features=0.8, max_leaf_nodes=None,\n",
       "              min_samples_leaf=10, min_samples_split=20,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=50,\n",
       "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(**params)\n",
    "clf.fit(newX[columns],newY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature transformations with ensembles of trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_score(clf, columns):\n",
    "    SLOT1 = range(44,152,12)\n",
    "    SLOT2 = range(56,152,12)\n",
    "    RANGE = {'2016-01-23': SLOT1, '2016-01-25': SLOT2, '2016-01-27': SLOT1, '2016-01-29': SLOT2, '2016-01-31': SLOT1}\n",
    "    scores = []\n",
    "    for day in RANGE.keys():\n",
    "        x = select_last_points(day, RANGE[day])\n",
    "        score = score3(day, clf.predict(x[columns]))\n",
    "        scores.append(score * x.shape[0])\n",
    "        print '\\t score: {}'.format(score)\n",
    "    print np.array(scores).sum()/2838"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LogisticRegression' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-387-a0a2e93c7021>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mgrd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0menc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOneHotEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mlm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0menc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mlm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_lr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_lr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'LogisticRegression' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_train_lr, y_train, y_train_lr = train_test_split(newX[columns],\n",
    "                                                            newY,\n",
    "                                                            test_size=0.5)\n",
    "grd = GradientBoostingClassifier(**params)\n",
    "grd.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select data from 2016-01-31 on [ 44  56  68  80  92 104 116 128 140]\n",
      "\t shape: (594, 38)\n",
      "\t score: 0.514295689059\n",
      "Select data from 2016-01-23 on [ 44  56  68  80  92 104 116 128 140]\n",
      "\t shape: (594, 38)\n",
      "\t score: 0.464276793287\n",
      "Select data from 2016-01-29 on [ 56  68  80  92 104 116 128 140]\n",
      "\t shape: (528, 38)\n",
      "\t score: 0.538297314982\n",
      "Select data from 2016-01-27 on [ 44  56  68  80  92 104 116 128 140]\n",
      "\t shape: (594, 38)\n",
      "\t score: 0.509096692953\n",
      "Select data from 2016-01-25 on [ 56  68  80  92 104 116 128 140]\n",
      "\t shape: (528, 38)\n",
      "\t score: 0.541246695547\n",
      "0.512218015394\n"
     ]
    }
   ],
   "source": [
    "get_score(grd, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "enc = OneHotEncoder()\n",
    "lm = LogisticRegression()\n",
    "enc.fit(grd.apply(X_train)[:, :, 0])\n",
    "lm.fit(enc.transform(grd.apply(X_train_lr)[:, :, 0]), y_train_lr)\n",
    "# lm.fit(X_train_lr, y_train_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select data from 2016-01-31 on [ 44  56  68  80  92 104 116 128 140]\n",
      "\t shape: (594, 38)\n",
      "\t score: 0.908838025346\n",
      "Select data from 2016-01-23 on [ 44  56  68  80  92 104 116 128 140]\n",
      "\t shape: (594, 38)\n",
      "\t score: 0.904813715905\n",
      "Select data from 2016-01-29 on [ 56  68  80  92 104 116 128 140]\n",
      "\t shape: (528, 38)\n",
      "\t score: 0.914107711282\n",
      "Select data from 2016-01-27 on [ 44  56  68  80  92 104 116 128 140]\n",
      "\t shape: (594, 38)\n",
      "\t score: 0.900150672539\n",
      "Select data from 2016-01-25 on [ 56  68  80  92 104 116 128 140]\n",
      "\t shape: (528, 38)\n",
      "\t score: 0.909535937323\n",
      "0.90728769565\n"
     ]
    }
   ],
   "source": [
    "SLOT1 = range(44,152,12)\n",
    "SLOT2 = range(56,152,12)\n",
    "RANGE = {'2016-01-23': SLOT1, '2016-01-25': SLOT2, '2016-01-27': SLOT1, '2016-01-29': SLOT2, '2016-01-31': SLOT1}\n",
    "scores = []\n",
    "for day in RANGE.keys():\n",
    "    x = select_last_points(day, RANGE[day])\n",
    "    y_pred_grd_lm = lm.predict_proba(enc.transform(grd.apply(x[columns])[:, :, 0]))[:, 1]\n",
    "    score = score3(day, pd.Series(y_pred_grd_lm, index=x.index))\n",
    "    scores.append(score * x.shape[0])\n",
    "    print '\\t score: {}'.format(score)\n",
    "print np.array(scores).sum()/2838"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore which gap is the most common errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score4(day, pred):\n",
    "    a = test_order[day].reindex(index(D_range, S_range[day])).fillna(0)\n",
    "    ans = a['gap'].values\n",
    "    pred = pred[ans>0]\n",
    "    ans = ans[ans>0]\n",
    "    gap = (ans - pred) / ans\n",
    "    temp = pd.DataFrame(ans, index=pred.index,columns=[day])\n",
    "    return temp, pd.DataFrame(np.fabs(gap),columns=[day])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select data from 2016-01-31 on [ 44  56  68  80  92 104 116 128 140]\n",
      "\t shape: (594, 38)\n",
      "Select data from 2016-01-23 on [ 44  56  68  80  92 104 116 128 140]\n",
      "\t shape: (594, 38)\n",
      "Select data from 2016-01-29 on [ 56  68  80  92 104 116 128 140]\n",
      "\t shape: (528, 38)\n",
      "Select data from 2016-01-27 on [ 44  56  68  80  92 104 116 128 140]\n",
      "\t shape: (594, 38)\n",
      "Select data from 2016-01-25 on [ 56  68  80  92 104 116 128 140]\n",
      "\t shape: (528, 38)\n"
     ]
    }
   ],
   "source": [
    "SLOT1 = range(44,152,12)\n",
    "SLOT2 = range(56,152,12)\n",
    "RANGE = {'2016-01-23': SLOT1, '2016-01-25': SLOT2, '2016-01-27': SLOT1, '2016-01-29': SLOT2, '2016-01-31': SLOT1}\n",
    "ans = pd.DataFrame()\n",
    "scores = pd.DataFrame()\n",
    "for day in RANGE.keys():\n",
    "    x = select_last_points(day, RANGE[day])\n",
    "    a, s = score4(day, pd.Series(clf.predict(x[columns]), index=x.index))\n",
    "    ans = pd.concat([ans, a], axis=1)\n",
    "    scores = pd.concat([scores, s], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1     25\n",
      "5     17\n",
      "4     16\n",
      "2     11\n",
      "6     11\n",
      "3      9\n",
      "9      8\n",
      "8      6\n",
      "10     6\n",
      "Name: 2016-01-23, dtype: int64\n",
      "1     16\n",
      "2     16\n",
      "5     13\n",
      "3     13\n",
      "9     11\n",
      "4      9\n",
      "7      8\n",
      "6      6\n",
      "10     6\n",
      "Name: 2016-01-25, dtype: int64\n",
      "1     26\n",
      "5     17\n",
      "3     15\n",
      "4     14\n",
      "2     12\n",
      "6      8\n",
      "7      5\n",
      "11     4\n",
      "13     3\n",
      "22     3\n",
      "20     3\n",
      "19     3\n",
      "15     3\n",
      "12     3\n",
      "10     3\n",
      "Name: 2016-01-27, dtype: int64\n",
      "1     16\n",
      "2     12\n",
      "4     12\n",
      "6     11\n",
      "7     11\n",
      "3     10\n",
      "5      6\n",
      "10     5\n",
      "Name: 2016-01-29, dtype: int64\n",
      "1     21\n",
      "2     19\n",
      "6     12\n",
      "3      9\n",
      "5      9\n",
      "4      8\n",
      "8      8\n",
      "10     8\n",
      "Name: 2016-01-31, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "worst = scores[(scores>=0.8).any(1)]\n",
    "print ans.loc[worst.index]['2016-01-23'].value_counts()[:10]\n",
    "print ans.loc[worst.index]['2016-01-25'].value_counts()[:10]\n",
    "print ans.loc[worst.index]['2016-01-27'].value_counts()[:10]\n",
    "print ans.loc[worst.index]['2016-01-29'].value_counts()[:10]\n",
    "print ans.loc[worst.index]['2016-01-31'].value_counts()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method3 by GradientBoosting on regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "slot1 = range(45,153,12) # Last time slot of test slot for day 23, 27, 31\n",
    "slot2 = range(57,153,12) # Last time slot of test slot for day 25, 29\n",
    "S_range = {'2016-01-23':slot1, '2016-01-25':slot2, '2016-01-27':slot1, '2016-01-29':slot2, '2016-01-31':slot1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write3(x, day, slot, regr, mode):\n",
    "    with open('ans3_v1.csv', mode) as f:\n",
    "        writer = csv.writer(f, delimiter=',')\n",
    "        for D in D_range:\n",
    "            for S in slot:\n",
    "                key = (D,S)\n",
    "                if key in x.index:\n",
    "                    gap = x['gap'].loc[key] + regr.predict(x.loc[key].reshape(1, -1))[0]\n",
    "                else:\n",
    "                    gap = 1\n",
    "                gap = 0 if gap < 0 else gap\n",
    "                writer.writerow([str(D),'{}-{}'.format(day,S+1), '{:.15f}'.format(gap)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ans3_v1.csv\n",
    "# params = {'loss': 'huber', 'alpha': 0.9, 'n_estimators':250, 'max_features':0.5, 'random_state':1,\n",
    "#           'warm_start':False,'max_depth': 3, 'learning_rate': 0.1, 'subsample': 1.0}\n",
    "#-----brand new turing\n",
    "params = {'loss': 'huber', 'alpha': 0.9, 'n_estimators':20, 'max_features':1.0, 'random_state':1,\n",
    "          'warm_start':False,'max_depth': 10, 'learning_rate': 0.25, 'subsample': 0.85,\n",
    "          'min_samples_leaf': 25, 'min_samples_split':100}\n",
    "\n",
    "# Paramters need to be searched\n",
    "parameters = {'n_estimators': np.arange(100,600,150)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Searching best parameters\n",
    "# scoring_function = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "# regr = grid_search.GridSearchCV(GradientBoostingRegressor(**params), \n",
    "#                                 param_grid=parameters, scoring=scoring_function, cv=3)\n",
    "# regr.fit(X, Y)\n",
    "# Regr = regr.best_estimator_\n",
    "\n",
    "Regr = GradientBoostingRegressor(**params)\n",
    "Regr.fit(X, Y)\n",
    "print Regr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# max_features: sqrt -> 0.5 : 0.538287 -> 0.528706599387\n",
    "# max_features: 0.5 -> 0.8 : 0.528706599387 -> 0.530272920336\n",
    "#-----brand new turing\n",
    "# alpha: 0.9 -> 0.6 : 0.537699383041 -> 0.576867122284\n",
    "# learning_rate: 0.2 : 0.536744595218\n",
    "SLOT1 = range(44,152,12)\n",
    "SLOT2 = range(56,152,12)\n",
    "RANGE = {'2016-01-23': SLOT1, '2016-01-25': SLOT2, '2016-01-27': SLOT1, '2016-01-29': SLOT2, '2016-01-31': SLOT1}\n",
    "scores = []\n",
    "for day in RANGE.keys():\n",
    "    x = select_last_points(day, RANGE[day])\n",
    "    score = score3(day, x['gap']+Regr.predict(x))\n",
    "    scores.append(score * x.shape[0])\n",
    "    print '\\t score: {}'.format(score)\n",
    "print np.array(scores).sum()/2838"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing ANS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SLOT1 = range(45,153,12)\n",
    "SLOT2 = range(57,153,12)\n",
    "RANGE = {'2016-01-23': SLOT1, '2016-01-25': SLOT2, '2016-01-27': SLOT1, '2016-01-29': SLOT2, '2016-01-31': SLOT1}\n",
    "scores = []\n",
    "for day in RANGE.keys():\n",
    "    x = select_last_points(day, RANGE[day])\n",
    "    write3(x, day, S_range[day], Regr, 'a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Method 2 by using interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "slot1 = range(45,153,12)\n",
    "slot2 = range(57,153,12)\n",
    "S_range = {'2016-01-22':slot1, '2016-01-24':slot2, '2016-01-26':slot1, '2016-01-28':slot2, '2016-01-30':slot1}\n",
    "D_range = range(1,67)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Day_range = {'2016-01-22':pd.date_range('1/2/2016', periods=3, freq='7D'),\n",
    "             '2016-01-24':pd.date_range('1/3/2016', periods=3, freq='7D'),\n",
    "             '2016-01-26':pd.date_range('1/5/2016', periods=3, freq='7D'),\n",
    "             '2016-01-28':pd.date_range('1/7/2016', periods=3, freq='7D'),\n",
    "             '2016-01-30':pd.date_range('1/9/2016', periods=2, freq='7D')}\n",
    "def naive_score2(day):\n",
    "    ans = test_order[day].select(lambda x: x[1] in S_range[day])\n",
    "    \n",
    "    \n",
    "    deltas = []\n",
    "    for d in Day_range[day]:\n",
    "        data = train_order[str(d.date())].reindex([x for x in itertools.product(D_range,range(1,145))]).fillna(0)\n",
    "        data = data.diff().shift(-1)\n",
    "        data = data.loc[ans.index]\n",
    "        deltas.append(data)\n",
    "\n",
    "    delta = deltas[0]\n",
    "    for i in range(1,len(deltas)):\n",
    "        delta.add(deltas[i], fill_value=0)\n",
    "    pred = test_order[day].shift().loc[ans.index].fillna(0)+(delta/len(deltas))\n",
    "    gap = (ans - pred) / ans\n",
    "\n",
    "    return gap.abs().sum()/(66*len(S_range[day]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print naive_score2('2016-01-22')\n",
    "print naive_score2('2016-01-24')\n",
    "print naive_score2('2016-01-26')\n",
    "print naive_score2('2016-01-28')\n",
    "print naive_score2('2016-01-30')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def slope(day):\n",
    "    base_points = test_order[day].select(lambda x: x[1] in S_range[day])\n",
    "    deltas = []\n",
    "    for d in Day_range[day]:\n",
    "        data = train_order[str(d.date())].reindex([x for x in itertools.product(D_range,range(1,145))]).fillna(0)\n",
    "        data = data.diff().shift(-1)\n",
    "        deltas.append(data)\n",
    "    delta = deltas[0]\n",
    "    for i in range(1,len(deltas)):\n",
    "        delta = delta + deltas[i]\n",
    "    return base_points, delta/len(deltas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write2(day, base_points, slot, delta, mode):\n",
    "    with open('ans.csv', mode) as f:\n",
    "        writer = csv.writer(f, delimiter=',')\n",
    "        for D in range(1,67):\n",
    "            for S in slot:\n",
    "                key = (D,S-1)\n",
    "                if key in base_points.index:\n",
    "                    gap = base_points['gap'].loc[key] + delta['gap'].loc[key]\n",
    "                    gap = base_points['gap'].loc[key] if gap < 0 else gap\n",
    "                else:\n",
    "                    gap = 0.0\n",
    "                writer.writerow([D,'{}-{}'.format(day,S), '{:.3f}'.format(gap)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Day22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "day = '2016-01-22'\n",
    "base_points, delta = slope(day)\n",
    "write2(day, base_points, test_slot1, delta, 'w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Day24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "day = '2016-01-24'\n",
    "base_points, delta = slope(day)\n",
    "write2(day, base_points, test_slot2, delta, 'a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Day26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "day = '2016-01-26'\n",
    "base_points, delta = slope(day)\n",
    "write2(day, base_points, test_slot1, delta, 'a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Day28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "day = '2016-01-28'\n",
    "base_points, delta = slope(day)\n",
    "write2(day, base_points, test_slot2, delta, 'a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Day30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "day = '2016-01-30'\n",
    "base_points, delta = slope(day)\n",
    "write2(day, base_points, test_slot1, delta, 'a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict the score of naive method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Day_range = {'2016-01-22':pd.date_range('1/1/2016', periods=3, freq='7D'),\n",
    "             '2016-01-24':pd.date_range('1/3/2016', periods=3, freq='7D'),\n",
    "             '2016-01-26':pd.date_range('1/5/2016', periods=3, freq='7D'),\n",
    "             '2016-01-28':pd.date_range('1/7/2016', periods=3, freq='7D'),\n",
    "             '2016-01-30':pd.date_range('1/9/2016', periods=2, freq='7D')}\n",
    "def naive_score1(day):\n",
    "    ans = test_order[day].select(lambda x: x[1] in S_range[day])\n",
    "    \n",
    "    prediction = []\n",
    "    for d in Day_range[day]:\n",
    "        data = train_order[str(d.date())]\n",
    "        data = data.loc[ans.index].fillna(0)\n",
    "        prediction.append(data)\n",
    "\n",
    "    pred = prediction[0]\n",
    "    for i in range(1,len(prediction)):\n",
    "        pred.add(prediction[i], fill_value=0)\n",
    "    pred = pred/len(prediction)\n",
    "    gap = (ans - pred) / ans\n",
    "\n",
    "    return gap.abs().sum()/(66*len(S_range[day]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print naive_score1('2016-01-22')\n",
    "print naive_score1('2016-01-24')\n",
    "print naive_score1('2016-01-26')\n",
    "print naive_score1('2016-01-28')\n",
    "print naive_score1('2016-01-30')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Method 1 by using mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_slot1 = range(46,154,12)\n",
    "test_slot2 = range(58,154,12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Day22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_day22 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for day in pd.date_range('1/1/2016', periods=3, freq='7D'):\n",
    "    # Read data\n",
    "    order = pd.read_table(path['order'].format(day.date()), header=None, usecols=[1,3,6],\n",
    "                      names=['driver', 'district', 'time'])\n",
    "    # Select NA for calculating the value of gap\n",
    "    order = order[order['driver'].isnull()] \n",
    "    # Translating hash to id\n",
    "    order['district'] = order['district'].apply(lambda x: district[x])\n",
    "    # Translating timestamp to time_id\n",
    "    order['time'] = pd.to_datetime(order['time'])\n",
    "    order['time'] = (order['time'] - day) / M / 10 + 1\n",
    "    order['time'] = order['time'].astype(int)\n",
    "    # Grouping by district and time\n",
    "    test_day22.append(order.groupby(['district', 'time']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('ans.csv', 'w') as f:\n",
    "    writer = csv.writer(f, delimiter=',')\n",
    "    for D in range(1,67):\n",
    "        for S in test_slot1:\n",
    "            key = (D,S)\n",
    "            gap = []\n",
    "            for data in test_day22:\n",
    "                if key in data.groups:\n",
    "                    gap.append(data.get_group(key).shape[0])\n",
    "                else:\n",
    "                    gap.append(0)\n",
    "            writer.writerow([D,'2016-01-22-{}'.format(S), '{:.3f}'.format(np.mean(gap))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Day24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_day24 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for day in pd.date_range('1/3/2016', periods=3, freq='7D'):\n",
    "    # Read data\n",
    "    order = pd.read_table(path['order'].format(day.date()), header=None, usecols=[1,3,6],\n",
    "                      names=['driver', 'district', 'time'])\n",
    "    # Select NA for calculating the value of gap\n",
    "    order = order[order['driver'].isnull()] \n",
    "    # Translating hash to id\n",
    "    order['district'] = order['district'].apply(lambda x: district[x])\n",
    "    # Translating timestamp to time_id\n",
    "    order['time'] = pd.to_datetime(order['time'])\n",
    "    order['time'] = (order['time'] - day) / M / 10 + 1\n",
    "    order['time'] = order['time'].astype(int)\n",
    "    # Grouping by district and time\n",
    "    test_day24.append(order.groupby(['district', 'time']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('ans.csv', 'a') as f:\n",
    "    writer = csv.writer(f, delimiter=',')\n",
    "    for D in range(1,67):\n",
    "        for S in test_slot2:\n",
    "            key = (D,S)\n",
    "            gap = []\n",
    "            for data in test_day24:\n",
    "                if key in data.groups:\n",
    "                    gap.append(data.get_group(key).shape[0])\n",
    "                else:\n",
    "                    gap.append(0)\n",
    "            writer.writerow([D,'2016-01-24-{}'.format(S), '{:.3f}'.format(np.mean(gap))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Day26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_day26 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for day in pd.date_range('1/5/2016', periods=3, freq='7D'):\n",
    "    # Read data\n",
    "    order = pd.read_table(path['order'].format(day.date()), header=None, usecols=[1,3,6],\n",
    "                      names=['driver', 'district', 'time'])\n",
    "    # Select NA for calculating the value of gap\n",
    "    order = order[order['driver'].isnull()] \n",
    "    # Translating hash to id\n",
    "    order['district'] = order['district'].apply(lambda x: district[x])\n",
    "    # Translating timestamp to time_id\n",
    "    order['time'] = pd.to_datetime(order['time'])\n",
    "    order['time'] = (order['time'] - day) / M / 10 + 1\n",
    "    order['time'] = order['time'].astype(int)\n",
    "    # Grouping by district and time\n",
    "    test_day26.append(order.groupby(['district', 'time']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('ans.csv', 'a') as f:\n",
    "    writer = csv.writer(f, delimiter=',')\n",
    "    for D in range(1,67):\n",
    "        for S in test_slot1:\n",
    "            key = (D,S)\n",
    "            gap = []\n",
    "            for data in test_day26:\n",
    "                if key in data.groups:\n",
    "                    gap.append(data.get_group(key).shape[0])\n",
    "                else:\n",
    "                    gap.append(0)\n",
    "            writer.writerow([D,'2016-01-26-{}'.format(S), '{:.3f}'.format(np.mean(gap))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Day28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_day28 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for day in pd.date_range('1/7/2016', periods=3, freq='7D'):\n",
    "    # Read data\n",
    "    order = pd.read_table(path['order'].format(day.date()), header=None, usecols=[1,3,6],\n",
    "                      names=['driver', 'district', 'time'])\n",
    "    # Select NA for calculating the value of gap\n",
    "    order = order[order['driver'].isnull()] \n",
    "    # Translating hash to id\n",
    "    order['district'] = order['district'].apply(lambda x: district[x])\n",
    "    # Translating timestamp to time_id\n",
    "    order['time'] = pd.to_datetime(order['time'])\n",
    "    order['time'] = (order['time'] - day) / M / 10 + 1\n",
    "    order['time'] = order['time'].astype(int)\n",
    "    # Grouping by district and time\n",
    "    test_day28.append(order.groupby(['district', 'time']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('ans.csv', 'a') as f:\n",
    "    writer = csv.writer(f, delimiter=',')\n",
    "    for D in range(1,67):\n",
    "        for S in test_slot2:\n",
    "            key = (D,S)\n",
    "            gap = []\n",
    "            for data in test_day28:\n",
    "                if key in data.groups:\n",
    "                    gap.append(data.get_group(key).shape[0])\n",
    "                else:\n",
    "                    gap.append(0)\n",
    "            writer.writerow([D,'2016-01-28-{}'.format(S), '{:.3f}'.format(np.mean(gap))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Day30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_day30 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for day in pd.date_range('1/9/2016', periods=2, freq='7D'):\n",
    "    # Read data\n",
    "    order = pd.read_table(path['order'].format(day.date()), header=None, usecols=[1,3,6],\n",
    "                      names=['driver', 'district', 'time'])\n",
    "    # Select NA for calculating the value of gap\n",
    "    order = order[order['driver'].isnull()] \n",
    "    # Translating hash to id\n",
    "    order['district'] = order['district'].apply(lambda x: district[x])\n",
    "    # Translating timestamp to time_id\n",
    "    order['time'] = pd.to_datetime(order['time'])\n",
    "    order['time'] = (order['time'] - day) / M / 10 + 1\n",
    "    order['time'] = order['time'].astype(int)\n",
    "    # Grouping by district and time\n",
    "    test_day30.append(order.groupby(['district', 'time']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('ans.csv', 'a') as f:\n",
    "    writer = csv.writer(f, delimiter=',')\n",
    "    for D in range(1,67):\n",
    "        for S in test_slot1:\n",
    "            key = (D,S)\n",
    "            gap = []\n",
    "            for data in test_day30:\n",
    "                if key in data.groups:\n",
    "                    gap.append(data.get_group(key).shape[0])\n",
    "                else:\n",
    "                    gap.append(0)\n",
    "            writer.writerow([D,'2016-01-30-{}'.format(S), '{:.3f}'.format(np.mean(gap))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "day = '2016-01-01'\n",
    "Day = pd.Timestamp(day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "order = pd.read_table(path['order'].format(day), header=None, usecols=[1,3,6],\n",
    "                      names=['driver', 'district_id', 'time'])\n",
    "order = order[order['driver'].isnull()] # Select NA for calculating the value of gap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translating district hash to id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "order['district_id'] = order['district_id'].apply(lambda x: district[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translating timestamp to slot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "order['time'] = pd.to_datetime(order['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "order['time_slot'] = (order['time'] - Day) / M / 10 + 1\n",
    "order['time_slot'] = order['time_slot'].astype(int)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
