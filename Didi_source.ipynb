{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandas.tseries.offsets import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn import grid_search\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = {}\n",
    "path['train'] = {'order':'./training_data/order_data/order_data_{}', \n",
    "                    'weather': './training_data/weather_data/weather_data_{}',\n",
    "                    'traffic': './training_data/traffic_data/traffic_data_{}',\n",
    "                    'district':'./training_data/cluster_map/cluster_map',\n",
    "                    'poi':'./training_data/poi_data/poi_data'}\n",
    "path['test'] = {'order':'./test_data/order_data/order_data_{}_test', \n",
    "                'weather': './test_data/weather_data/weather_data_{}_test',\n",
    "                'traffic': './test_data/traffic_data/traffic_data_{}_test',\n",
    "                'district':'./test_data/cluster_map/cluster_map'}\n",
    "\n",
    "M = np.timedelta64(1, 'm') # base time stamp of 1 minute\n",
    "\n",
    "test_slot1 = range(46,154,12) # The test slot for day 22, 26, 30\n",
    "test_slot2 = range(58,154,12) # The test slot for day 24, 28\n",
    "\n",
    "D_range = range(1,67) # List of all district Ids\n",
    "T_range = range(1,145) # List of all time slots\n",
    "\n",
    "# Dictionary of District Info Table\n",
    "district_dict = pd.read_table(path['train']['district'], header=None, index_col=0)\n",
    "district_dict = district_dict[1].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Funtion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def index(district, slot):\n",
    "    if type(district) is int:\n",
    "        if type(slot) is int:\n",
    "            return [x for x in itertools.product([district],[slot])]\n",
    "        else:\n",
    "            return [x for x in itertools.product([district],slot)]\n",
    "    else:\n",
    "        if type(slot) is int:\n",
    "            return [x for x in itertools.product(district,[slot])]\n",
    "        else:\n",
    "            return [x for x in itertools.product(district,slot)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def District(df):\n",
    "    return df['district'].apply(lambda x: district_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Weekday(df):\n",
    "    return pd.to_datetime(df['time']).apply(lambda x: x.weekday())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Time(df, day):\n",
    "    time = pd.to_datetime(df['time'])\n",
    "    time = (time - pd.Timestamp(day)) / M / 10 + 1\n",
    "    return time.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocessing(day):\n",
    "    X = train_order[day].reindex(index(D_range,T_range)).fillna(0)\n",
    "    X['diff'] = pd.Series(index=X.index)\n",
    "    for D in D_range:\n",
    "        X.loc[(D, T_range),'diff'] = X.loc[(D, T_range),'gap'].diff().shift(-1).fillna(0)\n",
    "    X = pd.concat([X,train_traffic[day]],axis=1).dropna()\n",
    "    X = X.join(train_weather[day], on='time')\n",
    "    Y = X['diff']\n",
    "    X.drop('diff', axis=1, inplace=True)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting testing data and training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Traffic(day, option):\n",
    "    df = pd.read_table(path[option]['traffic'].format(day.date()), header=None,\n",
    "                      names=['district', 'LV1', 'LV2', 'LV3', 'LV4','time'])\n",
    "    df['district'] = District(df)\n",
    "    df['weekday'] = Weekday(df)\n",
    "    df['time'] = Time(df, str(day.date()))\n",
    "    for L in ['LV{}'.format(n) for n in range(1,5)]:\n",
    "        df[L]=df[L].apply(lambda x: x.split(':')[1]).astype(int)\n",
    "    index = pd.MultiIndex.from_arrays([df['district'].values, df['time'].values], names=('district', 'time'))\n",
    "    return pd.DataFrame({'weekday':df['weekday'].values,\n",
    "                         'district':df['district'].values,\n",
    "                         'time':df['time'].values,\n",
    "                         'LV1':df['LV1'].values, \n",
    "                         'LV2':df['LV2'].values,\n",
    "                         'LV3':df['LV3'].values,\n",
    "                         'LV4':df['LV4'].values,}, index=index).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DTG: District Time Gap\n",
    "def DTG(day, option):\n",
    "    df = pd.read_table(path[option]['order'].format(day.date()), header=None, usecols=[1,3,6],\n",
    "                      names=['driver', 'district', 'time'])\n",
    "    df = df[df['driver'].isnull()] \n",
    "    df['district'] = District(df)\n",
    "    df['time'] = Time(df, day.date())\n",
    "    Order = df.groupby(['district', 'time'])\n",
    "    return pd.DataFrame({'gap':Order.size()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Weather(day, option):\n",
    "    df = pd.read_table(path[option]['weather'].format(day.date()), header=None,\n",
    "                      names=['time', 'weather', 'temprature', 'pm2.5'])\n",
    "    df['time'] = Time(df, day.date())\n",
    "    df = df.drop_duplicates(subset='time')\n",
    "    DF = pd.DataFrame({'time': T_range}, columns=df.columns)\n",
    "    DF = DF.set_index('time')\n",
    "    DF.update(df.set_index('time'))\n",
    "    return DF.fillna(method='bfill').fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Dictionary of order data for testing indexed by date, cols = [gap]\n",
    "test_order = {} \n",
    "# Dictionary of traffic data for testing indexed by date, cols = [weekday, district, time, LV1, LV2, LV3, LV4]\n",
    "test_traffic = {}\n",
    "# Dictionary of weather data for testing indexed by date, cols = [temperature, weather, pm2.5]\n",
    "test_weather = {} \n",
    "for day in pd.date_range('1/22/2016', periods=5, freq='2D'):\n",
    "    test_order[str(day.date())] = DTG(day, 'test')\n",
    "    test_traffic[str(day.date())] = Traffic(day, 'test')\n",
    "    test_weather[str(day.date())] = Weather(day, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Check data\n",
    "print len(test_order.keys()) == 5\n",
    "print len(test_traffic.keys()) == 5\n",
    "print len(test_weather.keys()) == 5\n",
    "print all(test_order['2016-01-22'].columns.values == np.array(['gap']))\n",
    "print all(test_traffic['2016-01-22'].columns.values == np.array(['LV1', 'LV2', 'LV3', 'LV4', 'district', 'time', 'weekday']))\n",
    "print all(test_weather['2016-01-22'].columns.values == np.array(['weather', 'temprature', 'pm2.5']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Dictionary of order data for training indexed by date, cols = [gap]\n",
    "train_order = {}\n",
    "# Dictionary of traffic data for training indexed by date, cols = [weekday, district, time, LV1, LV2, LV3, LV4]\n",
    "train_traffic = {}\n",
    "# Dictionary of weather data for training indexed by date, cols = [temperature, weather, pm2.5]\n",
    "train_weather = {}\n",
    "for day in pd.date_range('1/1/2016', periods=21, freq='D'):\n",
    "    train_order[str(day.date())] = DTG(day, 'train')\n",
    "    train_traffic[str(day.date())] = Traffic(day, 'train')\n",
    "    train_weather[str(day.date())] = Weather(day, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Check data\n",
    "print len(train_order.keys()) == 21\n",
    "print len(train_traffic.keys()) == 21\n",
    "print len(train_weather.keys()) == 21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing training data X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "for d in pd.date_range('1/1/2016', periods=21, freq='D'):\n",
    "    tempX, tempY = preprocessing(str(d.date()))\n",
    "    X.append(tempX)\n",
    "    Y.append(tempY)\n",
    "X = pd.concat(X)\n",
    "X.sort_index(inplace=True)\n",
    "Y = pd.concat(Y)\n",
    "Y.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print len(X.columns) == 11\n",
    "print Y.shape[0] == X.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Developing Zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "POI = pd.DataFrame()\n",
    "with open(path['train']['poi'], 'r') as f:\n",
    "    for line in f:\n",
    "        POI = pd.concat( [POI, pd.DataFrame([tuple(line.strip().split('\\t'))])], ignore_index=True )\n",
    "POI.rename(columns={0:'district'}, inplace=True)\n",
    "POI['district'] = District(POI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Medthod3 by GradientBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "slot1 = range(45,153,12) # Last time slot of test slot for day 22, 26, 30\n",
    "slot2 = range(57,153,12) # Last time slot of test slot for day 24, 28\n",
    "S_range = {'2016-01-22':slot1, '2016-01-24':slot2, '2016-01-26':slot1, '2016-01-28':slot2, '2016-01-30':slot1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write3(x, day, slot, regr, mode):\n",
    "    with open('ans3.csv', mode) as f:\n",
    "        writer = csv.writer(f, delimiter=',')\n",
    "        for D in D_range:\n",
    "            for S in slot:\n",
    "                key = (D,S)\n",
    "                if key in x.index:\n",
    "                    gap = x['gap'].loc[key] + regr.predict(x.loc[key].reshape(1, -1))[0]\n",
    "                else:\n",
    "                    gap = 1\n",
    "                gap = 0 if gap < 0 else gap\n",
    "                writer.writerow([str(D),'{}-{}'.format(day,S+1), '{:.3f}'.format(gap)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def score3(day, pred):\n",
    "    ans = test_order[day].reindex(index(D_range, S_range[day])).fillna(0)\n",
    "    ans = ans['gap'].values\n",
    "    pred = pred[ans>0]\n",
    "    ans = ans[ans>0]\n",
    "    gap = (ans - pred) / ans\n",
    "    return np.fabs(gap).sum()/ans.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Day22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Predict Score on this day\n",
    "day = '2016-01-22'\n",
    "# all areas mixed: 0.770059708462\n",
    "params = {'loss': 'huber', 'alpha': 0.9,\n",
    "          'max_depth': 3, 'learning_rate': 0.1, 'subsample': 1.0}\n",
    "\n",
    "# Paramters need to be searched\n",
    "parameters = {'n_estimators': np.arange(100,600,150)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingRegressor(alpha=0.9, init=None, learning_rate=0.1,\n",
      "             loss='huber', max_depth=3, max_features=None,\n",
      "             max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2,\n",
      "             min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "             presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "             warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "# Searching best parameters\n",
    "scoring_function = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "regr = grid_search.GridSearchCV(GradientBoostingRegressor(**params), \n",
    "                                param_grid=parameters, scoring=scoring_function, cv=3)\n",
    "regr.fit(X, Y)\n",
    "Regr = regr.best_estimator_\n",
    "\n",
    "# Regr = GradientBoostingRegressor(**params)\n",
    "Regr.fit(X, Y)\n",
    "print Regr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# alpha: 0.9 -> 0.1 : 0.775124360324 -> 1.03167874288\n",
    "# loss: quantile -> ls : 0.775124360324 -> 0.686632655895\n",
    "# loss: quantile -> huber : 0.775124360324 -> 0.559654872126\n",
    "# learning_rate: 0.1 -> 0.9 : 0.559654872126 -> 0.584819846794\n",
    "# max_depth: 3 -> 5 : 0.584819846794 -> 0.624282373776\n",
    "# n_estimators: 250 -> 400 : 0.584819846794 -> 0.607329151263\n",
    "# subsample: 1.0 -> 0.5 : 0.559654872126 -> 0.56019559633\n",
    "x = test_order[day].reindex(index(D_range,S_range[day])).fillna(0)\n",
    "x = pd.concat([x,test_traffic[day]], axis=1, join_axes=[x.index]).dropna()\n",
    "x = x.join(test_weather[day], on='time')\n",
    "write3(x, day, S_range[day], Regr, 'a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Day24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "day = '2016-01-24'\n",
    "x = test_order[day].reindex(index(D_range,S_range[day])).fillna(0)\n",
    "x = pd.concat([x,test_traffic[day]], axis=1, join_axes=[x.index]).dropna()\n",
    "x = x.join(test_weather[day], on='time')\n",
    "write3(x, day, S_range[day], Regr, 'a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Day26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "day = '2016-01-26'\n",
    "x = test_order[day].reindex(index(D_range,S_range[day])).fillna(0)\n",
    "x = pd.concat([x,test_traffic[day]], axis=1, join_axes=[x.index]).dropna()\n",
    "x = x.join(test_weather[day], on='time')\n",
    "write3(x, day, S_range[day], Regr, 'a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Day28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "day = '2016-01-28'\n",
    "x = test_order[day].reindex(index(D_range,S_range[day])).fillna(0)\n",
    "x = pd.concat([x,test_traffic[day]], axis=1, join_axes=[x.index]).dropna()\n",
    "x = x.join(test_weather[day], on='time')\n",
    "write3(x, day, S_range[day], Regr, 'a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Day30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "day = '2016-01-30'\n",
    "x = test_order[day].reindex(index(D_range,S_range[day])).fillna(0)\n",
    "x = pd.concat([x,test_traffic[day]], axis=1, join_axes=[x.index]).dropna()\n",
    "x = x.join(test_weather[day], on='time')\n",
    "write3(x, day, S_range[day], Regr, 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for D in D_range:\n",
    "    regr = GradientBoostingRegressor(**params)\n",
    "\n",
    "    regr.fit(X,Y['gap'])\n",
    "    write3(x, D, day, test_slot1, regr, 'a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Method 2 by using interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "slot1 = range(45,153,12)\n",
    "slot2 = range(57,153,12)\n",
    "S_range = {'2016-01-22':slot1, '2016-01-24':slot2, '2016-01-26':slot1, '2016-01-28':slot2, '2016-01-30':slot1}\n",
    "D_range = range(1,67)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Day_range = {'2016-01-22':pd.date_range('1/2/2016', periods=3, freq='7D'),\n",
    "             '2016-01-24':pd.date_range('1/3/2016', periods=3, freq='7D'),\n",
    "             '2016-01-26':pd.date_range('1/5/2016', periods=3, freq='7D'),\n",
    "             '2016-01-28':pd.date_range('1/7/2016', periods=3, freq='7D'),\n",
    "             '2016-01-30':pd.date_range('1/9/2016', periods=2, freq='7D')}\n",
    "def naive_score2(day):\n",
    "    ans = test_order[day].select(lambda x: x[1] in S_range[day])\n",
    "    \n",
    "    \n",
    "    deltas = []\n",
    "    for d in Day_range[day]:\n",
    "        data = train_order[str(d.date())].reindex([x for x in itertools.product(D_range,range(1,145))]).fillna(0)\n",
    "        data = data.diff().shift(-1)\n",
    "        data = data.loc[ans.index]\n",
    "        deltas.append(data)\n",
    "\n",
    "    delta = deltas[0]\n",
    "    for i in range(1,len(deltas)):\n",
    "        delta.add(deltas[i], fill_value=0)\n",
    "    pred = test_order[day].shift().loc[ans.index].fillna(0)+(delta/len(deltas))\n",
    "    gap = (ans - pred) / ans\n",
    "\n",
    "    return gap.abs().sum()/(66*len(S_range[day]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print naive_score2('2016-01-22')\n",
    "print naive_score2('2016-01-24')\n",
    "print naive_score2('2016-01-26')\n",
    "print naive_score2('2016-01-28')\n",
    "print naive_score2('2016-01-30')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def slope(day):\n",
    "    base_points = test_order[day].select(lambda x: x[1] in S_range[day])\n",
    "    deltas = []\n",
    "    for d in Day_range[day]:\n",
    "        data = train_order[str(d.date())].reindex([x for x in itertools.product(D_range,range(1,145))]).fillna(0)\n",
    "        data = data.diff().shift(-1)\n",
    "        deltas.append(data)\n",
    "    delta = deltas[0]\n",
    "    for i in range(1,len(deltas)):\n",
    "        delta = delta + deltas[i]\n",
    "    return base_points, delta/len(deltas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write2(day, base_points, slot, delta, mode):\n",
    "    with open('ans.csv', mode) as f:\n",
    "        writer = csv.writer(f, delimiter=',')\n",
    "        for D in range(1,67):\n",
    "            for S in slot:\n",
    "                key = (D,S-1)\n",
    "                if key in base_points.index:\n",
    "                    gap = base_points['gap'].loc[key] + delta['gap'].loc[key]\n",
    "                    gap = base_points['gap'].loc[key] if gap < 0 else gap\n",
    "                else:\n",
    "                    gap = 0.0\n",
    "                writer.writerow([D,'{}-{}'.format(day,S), '{:.3f}'.format(gap)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Day22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "day = '2016-01-22'\n",
    "base_points, delta = slope(day)\n",
    "write2(day, base_points, test_slot1, delta, 'w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Day24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "day = '2016-01-24'\n",
    "base_points, delta = slope(day)\n",
    "write2(day, base_points, test_slot2, delta, 'a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Day26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "day = '2016-01-26'\n",
    "base_points, delta = slope(day)\n",
    "write2(day, base_points, test_slot1, delta, 'a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Day28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "day = '2016-01-28'\n",
    "base_points, delta = slope(day)\n",
    "write2(day, base_points, test_slot2, delta, 'a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Day30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "day = '2016-01-30'\n",
    "base_points, delta = slope(day)\n",
    "write2(day, base_points, test_slot1, delta, 'a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict the score of naive method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Day_range = {'2016-01-22':pd.date_range('1/1/2016', periods=3, freq='7D'),\n",
    "             '2016-01-24':pd.date_range('1/3/2016', periods=3, freq='7D'),\n",
    "             '2016-01-26':pd.date_range('1/5/2016', periods=3, freq='7D'),\n",
    "             '2016-01-28':pd.date_range('1/7/2016', periods=3, freq='7D'),\n",
    "             '2016-01-30':pd.date_range('1/9/2016', periods=2, freq='7D')}\n",
    "def naive_score1(day):\n",
    "    ans = test_order[day].select(lambda x: x[1] in S_range[day])\n",
    "    \n",
    "    prediction = []\n",
    "    for d in Day_range[day]:\n",
    "        data = train_order[str(d.date())]\n",
    "        data = data.loc[ans.index].fillna(0)\n",
    "        prediction.append(data)\n",
    "\n",
    "    pred = prediction[0]\n",
    "    for i in range(1,len(prediction)):\n",
    "        pred.add(prediction[i], fill_value=0)\n",
    "    pred = pred/len(prediction)\n",
    "    gap = (ans - pred) / ans\n",
    "\n",
    "    return gap.abs().sum()/(66*len(S_range[day]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print naive_score1('2016-01-22')\n",
    "print naive_score1('2016-01-24')\n",
    "print naive_score1('2016-01-26')\n",
    "print naive_score1('2016-01-28')\n",
    "print naive_score1('2016-01-30')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Method 1 by using mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_slot1 = range(46,154,12)\n",
    "test_slot2 = range(58,154,12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Day22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_day22 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for day in pd.date_range('1/1/2016', periods=3, freq='7D'):\n",
    "    # Read data\n",
    "    order = pd.read_table(path['order'].format(day.date()), header=None, usecols=[1,3,6],\n",
    "                      names=['driver', 'district', 'time'])\n",
    "    # Select NA for calculating the value of gap\n",
    "    order = order[order['driver'].isnull()] \n",
    "    # Translating hash to id\n",
    "    order['district'] = order['district'].apply(lambda x: district[x])\n",
    "    # Translating timestamp to time_id\n",
    "    order['time'] = pd.to_datetime(order['time'])\n",
    "    order['time'] = (order['time'] - day) / M / 10 + 1\n",
    "    order['time'] = order['time'].astype(int)\n",
    "    # Grouping by district and time\n",
    "    test_day22.append(order.groupby(['district', 'time']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('ans.csv', 'w') as f:\n",
    "    writer = csv.writer(f, delimiter=',')\n",
    "    for D in range(1,67):\n",
    "        for S in test_slot1:\n",
    "            key = (D,S)\n",
    "            gap = []\n",
    "            for data in test_day22:\n",
    "                if key in data.groups:\n",
    "                    gap.append(data.get_group(key).shape[0])\n",
    "                else:\n",
    "                    gap.append(0)\n",
    "            writer.writerow([D,'2016-01-22-{}'.format(S), '{:.3f}'.format(np.mean(gap))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Day24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_day24 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for day in pd.date_range('1/3/2016', periods=3, freq='7D'):\n",
    "    # Read data\n",
    "    order = pd.read_table(path['order'].format(day.date()), header=None, usecols=[1,3,6],\n",
    "                      names=['driver', 'district', 'time'])\n",
    "    # Select NA for calculating the value of gap\n",
    "    order = order[order['driver'].isnull()] \n",
    "    # Translating hash to id\n",
    "    order['district'] = order['district'].apply(lambda x: district[x])\n",
    "    # Translating timestamp to time_id\n",
    "    order['time'] = pd.to_datetime(order['time'])\n",
    "    order['time'] = (order['time'] - day) / M / 10 + 1\n",
    "    order['time'] = order['time'].astype(int)\n",
    "    # Grouping by district and time\n",
    "    test_day24.append(order.groupby(['district', 'time']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('ans.csv', 'a') as f:\n",
    "    writer = csv.writer(f, delimiter=',')\n",
    "    for D in range(1,67):\n",
    "        for S in test_slot2:\n",
    "            key = (D,S)\n",
    "            gap = []\n",
    "            for data in test_day24:\n",
    "                if key in data.groups:\n",
    "                    gap.append(data.get_group(key).shape[0])\n",
    "                else:\n",
    "                    gap.append(0)\n",
    "            writer.writerow([D,'2016-01-24-{}'.format(S), '{:.3f}'.format(np.mean(gap))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Day26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_day26 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for day in pd.date_range('1/5/2016', periods=3, freq='7D'):\n",
    "    # Read data\n",
    "    order = pd.read_table(path['order'].format(day.date()), header=None, usecols=[1,3,6],\n",
    "                      names=['driver', 'district', 'time'])\n",
    "    # Select NA for calculating the value of gap\n",
    "    order = order[order['driver'].isnull()] \n",
    "    # Translating hash to id\n",
    "    order['district'] = order['district'].apply(lambda x: district[x])\n",
    "    # Translating timestamp to time_id\n",
    "    order['time'] = pd.to_datetime(order['time'])\n",
    "    order['time'] = (order['time'] - day) / M / 10 + 1\n",
    "    order['time'] = order['time'].astype(int)\n",
    "    # Grouping by district and time\n",
    "    test_day26.append(order.groupby(['district', 'time']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('ans.csv', 'a') as f:\n",
    "    writer = csv.writer(f, delimiter=',')\n",
    "    for D in range(1,67):\n",
    "        for S in test_slot1:\n",
    "            key = (D,S)\n",
    "            gap = []\n",
    "            for data in test_day26:\n",
    "                if key in data.groups:\n",
    "                    gap.append(data.get_group(key).shape[0])\n",
    "                else:\n",
    "                    gap.append(0)\n",
    "            writer.writerow([D,'2016-01-26-{}'.format(S), '{:.3f}'.format(np.mean(gap))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Day28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_day28 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for day in pd.date_range('1/7/2016', periods=3, freq='7D'):\n",
    "    # Read data\n",
    "    order = pd.read_table(path['order'].format(day.date()), header=None, usecols=[1,3,6],\n",
    "                      names=['driver', 'district', 'time'])\n",
    "    # Select NA for calculating the value of gap\n",
    "    order = order[order['driver'].isnull()] \n",
    "    # Translating hash to id\n",
    "    order['district'] = order['district'].apply(lambda x: district[x])\n",
    "    # Translating timestamp to time_id\n",
    "    order['time'] = pd.to_datetime(order['time'])\n",
    "    order['time'] = (order['time'] - day) / M / 10 + 1\n",
    "    order['time'] = order['time'].astype(int)\n",
    "    # Grouping by district and time\n",
    "    test_day28.append(order.groupby(['district', 'time']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('ans.csv', 'a') as f:\n",
    "    writer = csv.writer(f, delimiter=',')\n",
    "    for D in range(1,67):\n",
    "        for S in test_slot2:\n",
    "            key = (D,S)\n",
    "            gap = []\n",
    "            for data in test_day28:\n",
    "                if key in data.groups:\n",
    "                    gap.append(data.get_group(key).shape[0])\n",
    "                else:\n",
    "                    gap.append(0)\n",
    "            writer.writerow([D,'2016-01-28-{}'.format(S), '{:.3f}'.format(np.mean(gap))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Day30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_day30 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for day in pd.date_range('1/9/2016', periods=2, freq='7D'):\n",
    "    # Read data\n",
    "    order = pd.read_table(path['order'].format(day.date()), header=None, usecols=[1,3,6],\n",
    "                      names=['driver', 'district', 'time'])\n",
    "    # Select NA for calculating the value of gap\n",
    "    order = order[order['driver'].isnull()] \n",
    "    # Translating hash to id\n",
    "    order['district'] = order['district'].apply(lambda x: district[x])\n",
    "    # Translating timestamp to time_id\n",
    "    order['time'] = pd.to_datetime(order['time'])\n",
    "    order['time'] = (order['time'] - day) / M / 10 + 1\n",
    "    order['time'] = order['time'].astype(int)\n",
    "    # Grouping by district and time\n",
    "    test_day30.append(order.groupby(['district', 'time']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('ans.csv', 'a') as f:\n",
    "    writer = csv.writer(f, delimiter=',')\n",
    "    for D in range(1,67):\n",
    "        for S in test_slot1:\n",
    "            key = (D,S)\n",
    "            gap = []\n",
    "            for data in test_day30:\n",
    "                if key in data.groups:\n",
    "                    gap.append(data.get_group(key).shape[0])\n",
    "                else:\n",
    "                    gap.append(0)\n",
    "            writer.writerow([D,'2016-01-30-{}'.format(S), '{:.3f}'.format(np.mean(gap))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "day = '2016-01-01'\n",
    "Day = pd.Timestamp(day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "order = pd.read_table(path['order'].format(day), header=None, usecols=[1,3,6],\n",
    "                      names=['driver', 'district_id', 'time'])\n",
    "order = order[order['driver'].isnull()] # Select NA for calculating the value of gap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translating district hash to id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "order['district_id'] = order['district_id'].apply(lambda x: district[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translating timestamp to slot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "order['time'] = pd.to_datetime(order['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "order['time_slot'] = (order['time'] - Day) / M / 10 + 1\n",
    "order['time_slot'] = order['time_slot'].astype(int)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
