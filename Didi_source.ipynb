{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandas.tseries.offsets import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn import grid_search\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = {}\n",
    "path['train'] = {'order':'./training_data/order_data/order_data_{}', \n",
    "                    'weather': './training_data/weather_data/weather_data_{}',\n",
    "                    'traffic': './training_data/traffic_data/traffic_data_{}',\n",
    "                    'district':'./training_data/cluster_map/cluster_map',\n",
    "                    'poi':'./training_data/poi_data/poi_data'}\n",
    "path['test'] = {'order':'./test_data/order_data/order_data_{}_test', \n",
    "                'weather': './test_data/weather_data/weather_data_{}_test',\n",
    "                'traffic': './test_data/traffic_data/traffic_data_{}_test',\n",
    "                'district':'./test_data/cluster_map/cluster_map',\n",
    "                'poi':'./test_data/poi_data/poi_data'}\n",
    "\n",
    "M = np.timedelta64(1, 'm') # base time stamp of 1 minute\n",
    "\n",
    "test_slot1 = range(46,154,12) # The test slot for day 22, 26, 30\n",
    "test_slot2 = range(58,154,12) # The test slot for day 24, 28\n",
    "\n",
    "D_range = range(1,67) # List of all district Ids\n",
    "T_range = range(1,145) # List of all time slots\n",
    "\n",
    "# Dictionary of District Info Table\n",
    "district_dict = pd.read_table(path['train']['district'], header=None, index_col=0)\n",
    "district_dict = district_dict[1].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Funtion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def index(district, slot):\n",
    "    if type(district) is int:\n",
    "        if type(slot) is int:\n",
    "            return [x for x in itertools.product([district],[slot])]\n",
    "        else:\n",
    "            return [x for x in itertools.product([district],slot)]\n",
    "    else:\n",
    "        if type(slot) is int:\n",
    "            return [x for x in itertools.product(district,[slot])]\n",
    "        else:\n",
    "            return [x for x in itertools.product(district,slot)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def District(df):\n",
    "    return df['district'].apply(lambda x: district_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Weekday(df):\n",
    "    return pd.to_datetime(df['time']).apply(lambda x: x.weekday())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Time(df, day):\n",
    "    time = pd.to_datetime(df['time'])\n",
    "    time = (time - pd.Timestamp(day)) / M / 10 + 1\n",
    "    return time.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocessing(day):\n",
    "    X = train_order[day].reindex(index(D_range,T_range))\n",
    "    Y = pd.DataFrame(columns=X.columns,index=X.index)\n",
    "    for D in D_range:\n",
    "        Y.loc[(D, T_range),:] = X.loc[(D, T_range),:].diff().shift(-1).fillna(0)\n",
    "    X = pd.concat([X,train_traffic[day]],axis=1).dropna()\n",
    "    X = X.join(train_weather[day], on='time')\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting testing data and training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Traffic(day, option):\n",
    "    df = pd.read_table(path[option]['traffic'].format(day.date()), header=None,\n",
    "                      names=['district', 'LV1', 'LV2', 'LV3', 'LV4','time'])\n",
    "    df['district'] = District(df)\n",
    "    df['weekday'] = Weekday(df)\n",
    "    df['time'] = Time(df, str(day.date()))\n",
    "    for L in ['LV{}'.format(n) for n in range(1,5)]:\n",
    "        df[L]=df[L].apply(lambda x: x.split(':')[1]).astype(int)\n",
    "    index = pd.MultiIndex.from_arrays([df['district'].values, df['time'].values], names=('district', 'time'))\n",
    "    return pd.DataFrame({'weekday':df['weekday'].values,\n",
    "                         'district':df['district'].values,\n",
    "                         'time':df['time'].values,\n",
    "                         'LV1':df['LV1'].values, \n",
    "                         'LV2':df['LV2'].values,\n",
    "                         'LV3':df['LV3'].values,\n",
    "                         'LV4':df['LV4'].values,}, index=index).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DTG: District Time Gap\n",
    "def DTG(day, option):\n",
    "    df = pd.read_table(path[option]['order'].format(day.date()), header=None, usecols=[1,3,6],\n",
    "                      names=['driver', 'district', 'time'])\n",
    "    df = df[df['driver'].isnull()] \n",
    "    df['district'] = District(df)\n",
    "    df['time'] = Time(df, day.date())\n",
    "    Order = df.groupby(['district', 'time'])\n",
    "    return pd.DataFrame({'gap':Order.size()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Weather(day, option):\n",
    "    df = pd.read_table(path[option]['weather'].format(day.date()), header=None,\n",
    "                      names=['time', 'weather', 'temprature', 'pm2.5'])\n",
    "    df['time'] = Time(df, day.date())\n",
    "    df = df.drop_duplicates(subset='time')\n",
    "    DF = pd.DataFrame({'time': T_range}, columns=df.columns)\n",
    "    DF = DF.set_index('time')\n",
    "    DF.update(df.set_index('time'))\n",
    "    return DF.fillna(method='bfill').fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Dictionary of order data for testing indexed by date, cols = [gap]\n",
    "test_order = {} \n",
    "# Dictionary of traffic data for testing indexed by date, cols = [weekday, district, time, LV1, LV2, LV3, LV4]\n",
    "test_traffic = {}\n",
    "# Dictionary of weather data for testing indexed by date, cols = [temperature, weather, pm2.5]\n",
    "test_weather = {} \n",
    "for day in pd.date_range('1/22/2016', periods=5, freq='2D'):\n",
    "    test_order[str(day.date())] = DTG(day, 'test')\n",
    "    test_traffic[str(day.date())] = Traffic(day, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Dictionary of order data for training indexed by date, cols = [gap]\n",
    "train_order = {}\n",
    "# Dictionary of traffic data for training indexed by date, cols = [weekday, district, time, LV1, LV2, LV3, LV4]\n",
    "train_traffic = {}\n",
    "# Dictionary of weather data for training indexed by date, cols = [temperature, weather, pm2.5]\n",
    "train_weather = {}\n",
    "for day in pd.date_range('1/1/2016', periods=1, freq='D'):\n",
    "    train_order[str(day.date())] = DTG(day, 'train')\n",
    "    train_traffic[str(day.date())] = Traffic(day, 'train')\n",
    "    train_weather[str(day.date())] = Weather(day, 'train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing training data X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "for d in pd.date_range('1/1/2016', periods=1, freq='D'):\n",
    "    tempX, tempY = preprocessing(str(d.date()))\n",
    "    X.append(tempX)\n",
    "    Y.append(tempY)\n",
    "X = pd.concat(X)\n",
    "X.sort_index(inplace=True)\n",
    "Y = pd.concat(Y)\n",
    "Y.sort_index(inplace=True)\n",
    "Y = Y['gap']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Developing Zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               gap   LV1  LV2  LV3  LV4  district  time  weekday\n",
      "district time                                                   \n",
      "1        2       7  1399  318  102   94         1     2        4\n",
      "         3      10  1491  322   99   64         1     3        4\n",
      "         4       5  1490  287   98   78         1     4        4\n",
      "         5       1  1425  302   95   51         1     5        4\n",
      "         6       1  1327  313   94   66         1     6        4\n",
      "         7       6  1361  258   68   55         1     7        4\n",
      "         8       2  1395  280   97   69         1     8        4\n",
      "         9       6  1348  272   93   97         1     9        4\n",
      "         10      6  1417  236   93   53         1    10        4\n",
      "         11      2  1316  241   82   64         1    11        4\n",
      "         12      3  1393  254   65   65         1    12        4\n",
      "         13      1  1339  241   87   69         1    13        4\n",
      "         14      4  1390  198   69   47         1    14        4\n",
      "         15      3  1303  199   65   51         1    15        4\n",
      "         16     11  1296  190   60   60         1    16        4\n",
      "         17     20  1259  131   50   50         1    17        4\n",
      "         18     18  1277  161   47   52         1    18        4\n",
      "         19     11  1211  143   54   51         1    19        4\n",
      "         20      6  1160  163   39   51         1    20        4\n",
      "         21      2  1165  153   48   51         1    21        4\n",
      "         22      1  1115  140   49   47         1    22        4\n",
      "         23      3  1118  126   52   46         1    23        4\n",
      "         24      8  1061  141   34   38         1    24        4\n",
      "         25      1  1026  129   47   57         1    25        4\n",
      "         26      1  1120  129   44   48         1    26        4\n",
      "         27      5   982  145   45   40         1    27        4\n",
      "         29      4   978  139   54   43         1    29        4\n",
      "         30     13  1029  126   42   49         1    30        4\n",
      "         31     28  1018  117   43   58         1    31        4\n",
      "         32     17   995  142   42   46         1    32        4\n",
      "...            ...   ...  ...  ...  ...       ...   ...      ...\n",
      "66       57      1   347   60   16   15        66    57        4\n",
      "         65      1   267   42   13   12        66    65        4\n",
      "         66      1   285   52   10    7        66    66        4\n",
      "         68      1   296   49    5    3        66    68        4\n",
      "         69      2   280   45   11   17        66    69        4\n",
      "         72      1   323   50   22    9        66    72        4\n",
      "         73      1   306   42   11    4        66    73        4\n",
      "         74      1   294   49   13   17        66    74        4\n",
      "         80      1   292   33    9    7        66    80        4\n",
      "         84      1   266   74   22   16        66    84        4\n",
      "         90      5   287   78   18   11        66    90        4\n",
      "         91      3   328   68   13    4        66    91        4\n",
      "         92      3   264   73   14    7        66    92        4\n",
      "         95      1   282   76   15    9        66    95        4\n",
      "         100     1   311   65   18   16        66   100        4\n",
      "         101     1   286   61    8    2        66   101        4\n",
      "         102     1   270   93   22   10        66   102        4\n",
      "         103     4   312   73   15   11        66   103        4\n",
      "         104     2   269   99   13   17        66   104        4\n",
      "         105     2   263   97   21   24        66   105        4\n",
      "         106     1   270   97   28   15        66   106        4\n",
      "         112     1   272   75   19   10        66   112        4\n",
      "         115     1   270   86   26   13        66   115        4\n",
      "         117     1   261   99   28    7        66   117        4\n",
      "         118     1   270   64   16   22        66   118        4\n",
      "         123     2   326   65   20   11        66   123        4\n",
      "         125     1   267   54   24   26        66   125        4\n",
      "         129     1   280   55   10   14        66   129        4\n",
      "         136     1   300   28    7   16        66   136        4\n",
      "         137     1   244   50   11   13        66   137        4\n",
      "\n",
      "[5670 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "print X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Medthod3 by GradientBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "slot1 = range(45,153,12) # Last time slot of test slot for day 22, 26, 30\n",
    "slot2 = range(57,153,12) # Last time slot of test slot for day 24, 28\n",
    "S_range = {'2016-01-22':slot1, '2016-01-24':slot2, '2016-01-26':slot1, '2016-01-28':slot2, '2016-01-30':slot1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write3(x, district, day, slot, regr, mode):\n",
    "    with open('ans3.csv', mode) as f:\n",
    "        writer = csv.writer(f, delimiter=',')\n",
    "        for S in slot:\n",
    "            key = (district,S-1)\n",
    "            if key in x.index:\n",
    "                gap = x['gap'].loc[key] + regr.predict(x.loc[key].reshape(1, -1))[0]\n",
    "            else:\n",
    "                gap = 0\n",
    "            gap = 0 if gap < 0 else gap\n",
    "            writer.writerow([str(district),'{}-{}'.format(day,S), '{:.3f}'.format(gap)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def score3(day, pred):\n",
    "    ans = test_order[day].reindex(index(D_range, S_range[day])).fillna(0)\n",
    "    ans = ans['gap'].values\n",
    "    pred = pred[ans>0]\n",
    "    ans = ans[ans>0]\n",
    "    gap = (ans - pred) / ans\n",
    "    return np.fabs(gap).sum()/ans.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Day22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Predict Score on this day\n",
    "day = '2016-01-22'\n",
    "# all areas mixed: 0.770059708462\n",
    "params = {'loss': 'huber', 'alpha': 0.9, 'n_estimators': 250,\n",
    "          'max_depth': 3, 'learning_rate': 0.1, 'subsample': 1.0}\n",
    "\n",
    "# Paramters need to be searched\n",
    "parameters = {'n_estimators': np.arange(100,600,150)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Searching best parameters\n",
    "# scoring_function = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "# regr = grid_search.GridSearchCV(GradientBoostingRegressor(loss='quantile'), \n",
    "#                                 param_grid=parameters, scoring=scoring_function, cv=3)\n",
    "# regr.fit(X, Y)\n",
    "# Regr = regr.best_estimator_\n",
    "\n",
    "Regr = GradientBoostingRegressor(**params)\n",
    "Regr.fit(X, Y)\n",
    "print Regr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# alpha: 0.9 -> 0.1 : 0.775124360324 -> 1.03167874288\n",
    "# loss: quantile -> ls : 0.775124360324 -> 0.686632655895\n",
    "# loss: quantile -> huber : 0.775124360324 -> 0.559654872126\n",
    "# learning_rate: 0.1 -> 0.9 : 0.559654872126 -> 0.584819846794\n",
    "# max_depth: 3 -> 5 : 0.584819846794 -> 0.624282373776\n",
    "# n_estimators: 250 -> 400 : 0.584819846794 -> 0.607329151263\n",
    "# subsample: 1.0 -> 0.5 : 0.559654872126 -> 0.56019559633\n",
    "SLOT1 = range(44,152,12)\n",
    "x = test_order[day].reindex(index(D_range,SLOT1)).fillna(0)\n",
    "x = pd.concat([x,test_traffic[day]], axis=1, join_axes=[x.index]).fillna(0)\n",
    "print score3(day,x['gap']+Regr.predict(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Day24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "day = '2016-01-24'\n",
    "x = test_order[day].select(lambda x: x[1] in S_range[day])\n",
    "x = pd.concat([x,test_traffic[day]],axis=1).fillna(0)\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "for d in ['2016-01-03','2016-01-10','2016-01-17']:\n",
    "    tempX, tempY = preprocessing(d)\n",
    "    X.append(tempX)\n",
    "    Y.append(tempY)\n",
    "X = pd.concat(X)\n",
    "Y = pd.concat(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for D in D_range:\n",
    "    regr = GradientBoostingRegressor(**params)\n",
    "\n",
    "    regr.fit(X,Y['gap'])\n",
    "    write3(x, D, day, test_slot2, regr, 'a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Day26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "day = '2016-01-26'\n",
    "x = test_order[day].select(lambda x: x[1] in S_range[day])\n",
    "x = pd.concat([x,test_traffic[day]],axis=1).fillna(0)\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "for d in ['2016-01-05','2016-01-12','2016-01-19']:\n",
    "    tempX, tempY = preprocessing(d)\n",
    "    X.append(tempX)\n",
    "    Y.append(tempY)\n",
    "X = pd.concat(X)\n",
    "Y = pd.concat(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for D in D_range:\n",
    "    regr = GradientBoostingRegressor(**params)\n",
    "\n",
    "    regr.fit(X,Y['gap'])\n",
    "    write3(x, D, day, test_slot1, regr, 'a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Day28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "day = '2016-01-28'\n",
    "x = test_order[day].select(lambda x: x[1] in S_range[day])\n",
    "x = pd.concat([x,test_traffic[day]],axis=1).fillna(0)\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "for d in ['2016-01-07','2016-01-14','2016-01-21']:\n",
    "    tempX, tempY = preprocessing(d)\n",
    "    X.append(tempX)\n",
    "    Y.append(tempY)\n",
    "X = pd.concat(X)\n",
    "Y = pd.concat(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for D in D_range:\n",
    "    regr = GradientBoostingRegressor(**params)\n",
    "\n",
    "    regr.fit(X,Y['gap'])\n",
    "    write3(x, D, day, test_slot2, regr, 'a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Day30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "day = '2016-01-30'\n",
    "x = test_order[day].select(lambda x: x[1] in S_range[day])\n",
    "x = pd.concat([x,test_traffic[day]],axis=1).fillna(0)\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "for d in ['2016-01-09','2016-01-16']:\n",
    "    tempX, tempY = preprocessing(d)\n",
    "    X.append(tempX)\n",
    "    Y.append(tempY)\n",
    "X = pd.concat(X)\n",
    "Y = pd.concat(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for D in D_range:\n",
    "    regr = GradientBoostingRegressor(**params)\n",
    "\n",
    "    regr.fit(X,Y['gap'])\n",
    "    write3(x, D, day, test_slot1, regr, 'a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Method 2 by using interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "slot1 = range(45,153,12)\n",
    "slot2 = range(57,153,12)\n",
    "S_range = {'2016-01-22':slot1, '2016-01-24':slot2, '2016-01-26':slot1, '2016-01-28':slot2, '2016-01-30':slot1}\n",
    "D_range = range(1,67)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Day_range = {'2016-01-22':pd.date_range('1/2/2016', periods=3, freq='7D'),\n",
    "             '2016-01-24':pd.date_range('1/3/2016', periods=3, freq='7D'),\n",
    "             '2016-01-26':pd.date_range('1/5/2016', periods=3, freq='7D'),\n",
    "             '2016-01-28':pd.date_range('1/7/2016', periods=3, freq='7D'),\n",
    "             '2016-01-30':pd.date_range('1/9/2016', periods=2, freq='7D')}\n",
    "def naive_score2(day):\n",
    "    ans = test_order[day].select(lambda x: x[1] in S_range[day])\n",
    "    \n",
    "    \n",
    "    deltas = []\n",
    "    for d in Day_range[day]:\n",
    "        data = train_order[str(d.date())].reindex([x for x in itertools.product(D_range,range(1,145))]).fillna(0)\n",
    "        data = data.diff().shift(-1)\n",
    "        data = data.loc[ans.index]\n",
    "        deltas.append(data)\n",
    "\n",
    "    delta = deltas[0]\n",
    "    for i in range(1,len(deltas)):\n",
    "        delta.add(deltas[i], fill_value=0)\n",
    "    pred = test_order[day].shift().loc[ans.index].fillna(0)+(delta/len(deltas))\n",
    "    gap = (ans - pred) / ans\n",
    "\n",
    "    return gap.abs().sum()/(66*len(S_range[day]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print naive_score2('2016-01-22')\n",
    "print naive_score2('2016-01-24')\n",
    "print naive_score2('2016-01-26')\n",
    "print naive_score2('2016-01-28')\n",
    "print naive_score2('2016-01-30')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def slope(day):\n",
    "    base_points = test_order[day].select(lambda x: x[1] in S_range[day])\n",
    "    deltas = []\n",
    "    for d in Day_range[day]:\n",
    "        data = train_order[str(d.date())].reindex([x for x in itertools.product(D_range,range(1,145))]).fillna(0)\n",
    "        data = data.diff().shift(-1)\n",
    "        deltas.append(data)\n",
    "    delta = deltas[0]\n",
    "    for i in range(1,len(deltas)):\n",
    "        delta = delta + deltas[i]\n",
    "    return base_points, delta/len(deltas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write2(day, base_points, slot, delta, mode):\n",
    "    with open('ans.csv', mode) as f:\n",
    "        writer = csv.writer(f, delimiter=',')\n",
    "        for D in range(1,67):\n",
    "            for S in slot:\n",
    "                key = (D,S-1)\n",
    "                if key in base_points.index:\n",
    "                    gap = base_points['gap'].loc[key] + delta['gap'].loc[key]\n",
    "                    gap = base_points['gap'].loc[key] if gap < 0 else gap\n",
    "                else:\n",
    "                    gap = 0.0\n",
    "                writer.writerow([D,'{}-{}'.format(day,S), '{:.3f}'.format(gap)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Day22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "day = '2016-01-22'\n",
    "base_points, delta = slope(day)\n",
    "write2(day, base_points, test_slot1, delta, 'w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Day24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "day = '2016-01-24'\n",
    "base_points, delta = slope(day)\n",
    "write2(day, base_points, test_slot2, delta, 'a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Day26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "day = '2016-01-26'\n",
    "base_points, delta = slope(day)\n",
    "write2(day, base_points, test_slot1, delta, 'a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Day28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "day = '2016-01-28'\n",
    "base_points, delta = slope(day)\n",
    "write2(day, base_points, test_slot2, delta, 'a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Day30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "day = '2016-01-30'\n",
    "base_points, delta = slope(day)\n",
    "write2(day, base_points, test_slot1, delta, 'a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict the score of naive method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Day_range = {'2016-01-22':pd.date_range('1/1/2016', periods=3, freq='7D'),\n",
    "             '2016-01-24':pd.date_range('1/3/2016', periods=3, freq='7D'),\n",
    "             '2016-01-26':pd.date_range('1/5/2016', periods=3, freq='7D'),\n",
    "             '2016-01-28':pd.date_range('1/7/2016', periods=3, freq='7D'),\n",
    "             '2016-01-30':pd.date_range('1/9/2016', periods=2, freq='7D')}\n",
    "def naive_score1(day):\n",
    "    ans = test_order[day].select(lambda x: x[1] in S_range[day])\n",
    "    \n",
    "    prediction = []\n",
    "    for d in Day_range[day]:\n",
    "        data = train_order[str(d.date())]\n",
    "        data = data.loc[ans.index].fillna(0)\n",
    "        prediction.append(data)\n",
    "\n",
    "    pred = prediction[0]\n",
    "    for i in range(1,len(prediction)):\n",
    "        pred.add(prediction[i], fill_value=0)\n",
    "    pred = pred/len(prediction)\n",
    "    gap = (ans - pred) / ans\n",
    "\n",
    "    return gap.abs().sum()/(66*len(S_range[day]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print naive_score1('2016-01-22')\n",
    "print naive_score1('2016-01-24')\n",
    "print naive_score1('2016-01-26')\n",
    "print naive_score1('2016-01-28')\n",
    "print naive_score1('2016-01-30')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Method 1 by using mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_slot1 = range(46,154,12)\n",
    "test_slot2 = range(58,154,12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Day22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_day22 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for day in pd.date_range('1/1/2016', periods=3, freq='7D'):\n",
    "    # Read data\n",
    "    order = pd.read_table(path['order'].format(day.date()), header=None, usecols=[1,3,6],\n",
    "                      names=['driver', 'district', 'time'])\n",
    "    # Select NA for calculating the value of gap\n",
    "    order = order[order['driver'].isnull()] \n",
    "    # Translating hash to id\n",
    "    order['district'] = order['district'].apply(lambda x: district[x])\n",
    "    # Translating timestamp to time_id\n",
    "    order['time'] = pd.to_datetime(order['time'])\n",
    "    order['time'] = (order['time'] - day) / M / 10 + 1\n",
    "    order['time'] = order['time'].astype(int)\n",
    "    # Grouping by district and time\n",
    "    test_day22.append(order.groupby(['district', 'time']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('ans.csv', 'w') as f:\n",
    "    writer = csv.writer(f, delimiter=',')\n",
    "    for D in range(1,67):\n",
    "        for S in test_slot1:\n",
    "            key = (D,S)\n",
    "            gap = []\n",
    "            for data in test_day22:\n",
    "                if key in data.groups:\n",
    "                    gap.append(data.get_group(key).shape[0])\n",
    "                else:\n",
    "                    gap.append(0)\n",
    "            writer.writerow([D,'2016-01-22-{}'.format(S), '{:.3f}'.format(np.mean(gap))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Day24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_day24 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for day in pd.date_range('1/3/2016', periods=3, freq='7D'):\n",
    "    # Read data\n",
    "    order = pd.read_table(path['order'].format(day.date()), header=None, usecols=[1,3,6],\n",
    "                      names=['driver', 'district', 'time'])\n",
    "    # Select NA for calculating the value of gap\n",
    "    order = order[order['driver'].isnull()] \n",
    "    # Translating hash to id\n",
    "    order['district'] = order['district'].apply(lambda x: district[x])\n",
    "    # Translating timestamp to time_id\n",
    "    order['time'] = pd.to_datetime(order['time'])\n",
    "    order['time'] = (order['time'] - day) / M / 10 + 1\n",
    "    order['time'] = order['time'].astype(int)\n",
    "    # Grouping by district and time\n",
    "    test_day24.append(order.groupby(['district', 'time']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('ans.csv', 'a') as f:\n",
    "    writer = csv.writer(f, delimiter=',')\n",
    "    for D in range(1,67):\n",
    "        for S in test_slot2:\n",
    "            key = (D,S)\n",
    "            gap = []\n",
    "            for data in test_day24:\n",
    "                if key in data.groups:\n",
    "                    gap.append(data.get_group(key).shape[0])\n",
    "                else:\n",
    "                    gap.append(0)\n",
    "            writer.writerow([D,'2016-01-24-{}'.format(S), '{:.3f}'.format(np.mean(gap))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Day26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_day26 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for day in pd.date_range('1/5/2016', periods=3, freq='7D'):\n",
    "    # Read data\n",
    "    order = pd.read_table(path['order'].format(day.date()), header=None, usecols=[1,3,6],\n",
    "                      names=['driver', 'district', 'time'])\n",
    "    # Select NA for calculating the value of gap\n",
    "    order = order[order['driver'].isnull()] \n",
    "    # Translating hash to id\n",
    "    order['district'] = order['district'].apply(lambda x: district[x])\n",
    "    # Translating timestamp to time_id\n",
    "    order['time'] = pd.to_datetime(order['time'])\n",
    "    order['time'] = (order['time'] - day) / M / 10 + 1\n",
    "    order['time'] = order['time'].astype(int)\n",
    "    # Grouping by district and time\n",
    "    test_day26.append(order.groupby(['district', 'time']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('ans.csv', 'a') as f:\n",
    "    writer = csv.writer(f, delimiter=',')\n",
    "    for D in range(1,67):\n",
    "        for S in test_slot1:\n",
    "            key = (D,S)\n",
    "            gap = []\n",
    "            for data in test_day26:\n",
    "                if key in data.groups:\n",
    "                    gap.append(data.get_group(key).shape[0])\n",
    "                else:\n",
    "                    gap.append(0)\n",
    "            writer.writerow([D,'2016-01-26-{}'.format(S), '{:.3f}'.format(np.mean(gap))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Day28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_day28 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for day in pd.date_range('1/7/2016', periods=3, freq='7D'):\n",
    "    # Read data\n",
    "    order = pd.read_table(path['order'].format(day.date()), header=None, usecols=[1,3,6],\n",
    "                      names=['driver', 'district', 'time'])\n",
    "    # Select NA for calculating the value of gap\n",
    "    order = order[order['driver'].isnull()] \n",
    "    # Translating hash to id\n",
    "    order['district'] = order['district'].apply(lambda x: district[x])\n",
    "    # Translating timestamp to time_id\n",
    "    order['time'] = pd.to_datetime(order['time'])\n",
    "    order['time'] = (order['time'] - day) / M / 10 + 1\n",
    "    order['time'] = order['time'].astype(int)\n",
    "    # Grouping by district and time\n",
    "    test_day28.append(order.groupby(['district', 'time']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('ans.csv', 'a') as f:\n",
    "    writer = csv.writer(f, delimiter=',')\n",
    "    for D in range(1,67):\n",
    "        for S in test_slot2:\n",
    "            key = (D,S)\n",
    "            gap = []\n",
    "            for data in test_day28:\n",
    "                if key in data.groups:\n",
    "                    gap.append(data.get_group(key).shape[0])\n",
    "                else:\n",
    "                    gap.append(0)\n",
    "            writer.writerow([D,'2016-01-28-{}'.format(S), '{:.3f}'.format(np.mean(gap))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Day30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_day30 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for day in pd.date_range('1/9/2016', periods=2, freq='7D'):\n",
    "    # Read data\n",
    "    order = pd.read_table(path['order'].format(day.date()), header=None, usecols=[1,3,6],\n",
    "                      names=['driver', 'district', 'time'])\n",
    "    # Select NA for calculating the value of gap\n",
    "    order = order[order['driver'].isnull()] \n",
    "    # Translating hash to id\n",
    "    order['district'] = order['district'].apply(lambda x: district[x])\n",
    "    # Translating timestamp to time_id\n",
    "    order['time'] = pd.to_datetime(order['time'])\n",
    "    order['time'] = (order['time'] - day) / M / 10 + 1\n",
    "    order['time'] = order['time'].astype(int)\n",
    "    # Grouping by district and time\n",
    "    test_day30.append(order.groupby(['district', 'time']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('ans.csv', 'a') as f:\n",
    "    writer = csv.writer(f, delimiter=',')\n",
    "    for D in range(1,67):\n",
    "        for S in test_slot1:\n",
    "            key = (D,S)\n",
    "            gap = []\n",
    "            for data in test_day30:\n",
    "                if key in data.groups:\n",
    "                    gap.append(data.get_group(key).shape[0])\n",
    "                else:\n",
    "                    gap.append(0)\n",
    "            writer.writerow([D,'2016-01-30-{}'.format(S), '{:.3f}'.format(np.mean(gap))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "day = '2016-01-01'\n",
    "Day = pd.Timestamp(day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "order = pd.read_table(path['order'].format(day), header=None, usecols=[1,3,6],\n",
    "                      names=['driver', 'district_id', 'time'])\n",
    "order = order[order['driver'].isnull()] # Select NA for calculating the value of gap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translating district hash to id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "order['district_id'] = order['district_id'].apply(lambda x: district[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translating timestamp to slot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "order['time'] = pd.to_datetime(order['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "order['time_slot'] = (order['time'] - Day) / M / 10 + 1\n",
    "order['time_slot'] = order['time_slot'].astype(int)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
