{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandas.tseries.offsets import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import grid_search\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = {}\n",
    "path['train'] = {'order':'./training_data_2/order_data/order_data_{}', \n",
    "                    'weather': './training_data_2/weather_data/weather_data_{}',\n",
    "                    'traffic': './training_data_2/traffic_data/traffic_data_{}',\n",
    "                    'district':'./training_data_2/cluster_map/cluster_map',\n",
    "                    'poi':'./training_data_2/poi_data/poi_data'}\n",
    "path['test'] = {'order':'./test_data_2/order_data/order_data_{}_test', \n",
    "                'weather': './test_data_2/weather_data/weather_data_{}_test',\n",
    "                'traffic': './test_data_2/traffic_data/traffic_data_{}_test',\n",
    "                'district':'./test_data_2/cluster_map/cluster_map'}\n",
    "\n",
    "M = np.timedelta64(1, 'm') # base time stamp of 1 minute\n",
    "\n",
    "D_range = range(1,67) # List of all district Ids\n",
    "T_range = range(1,145) # List of all time slots\n",
    "\n",
    "test_slot1 = range(45,153,12) # Last time slot of test slot for day 23, 27, 31\n",
    "test_slot2 = range(57,153,12) # Last time slot of test slot for day 25, 29\n",
    "# List of all need to prediced time slots\n",
    "S_range = {'2016-01-23':test_slot1, '2016-01-25':test_slot2, '2016-01-27':test_slot1, \n",
    "           '2016-01-29':test_slot2, '2016-01-31':test_slot1}\n",
    "\n",
    "# Dictionary of District Info Table\n",
    "district_dict = pd.read_table(path['train']['district'], header=None, index_col=0)\n",
    "district_dict = district_dict[1].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print len(district_dict) == 66"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Funtion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def index(district, slot):\n",
    "    if type(district) is int:\n",
    "        if type(slot) is int:\n",
    "            return [x for x in itertools.product([district],[slot])]\n",
    "        else:\n",
    "            return [x for x in itertools.product([district],slot)]\n",
    "    else:\n",
    "        if type(slot) is int:\n",
    "            return [x for x in itertools.product(district,[slot])]\n",
    "        else:\n",
    "            return [x for x in itertools.product(district,slot)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def District(df):\n",
    "    return df['district'].apply(lambda x: district_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Weekday(df):\n",
    "    return pd.to_datetime(df['time']).apply(lambda x: x.weekday())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Time(df, day):\n",
    "    time = pd.to_datetime(df['time'])\n",
    "    time = (time - pd.Timestamp(day)) / M / 10 + 1\n",
    "    return time.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting testing data and training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Traffic(day, option):\n",
    "    df = pd.read_table(path[option]['traffic'].format(day.date()), header=None,\n",
    "                      names=['district', 'LV1', 'LV2', 'LV3', 'LV4','time'])\n",
    "    df['district'] = District(df)\n",
    "    df['weekday'] = Weekday(df)\n",
    "    df['time'] = Time(df, str(day.date()))\n",
    "    for L in ['LV{}'.format(n) for n in range(1,5)]:\n",
    "        df[L]=df[L].apply(lambda x: x.split(':')[1]).astype(int)\n",
    "    index = pd.MultiIndex.from_arrays([df['district'].values, df['time'].values], names=('district', 'time'))\n",
    "    return pd.DataFrame({'weekday':df['weekday'].values,\n",
    "                         'day':day.day,\n",
    "                         'district':df['district'].values,\n",
    "                         'time':df['time'].values,\n",
    "                         'LV1':df['LV1'].values, \n",
    "                         'LV2':df['LV2'].values,\n",
    "                         'LV3':df['LV3'].values,\n",
    "                         'LV4':df['LV4'].values,}, index=index).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DTG: District Time Gap\n",
    "def DTG(day, option):\n",
    "    df = pd.read_table(path[option]['order'].format(day.date()), header=None, usecols=[1,3,6],\n",
    "                      names=['driver', 'district', 'time'])\n",
    "    df = df[df['driver'].isnull()] \n",
    "    df['district'] = District(df)\n",
    "    df['time'] = Time(df, day.date())\n",
    "    Order = df.groupby(['district', 'time'])\n",
    "    return pd.DataFrame({'gap':Order.size()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Weather(day, option):\n",
    "    df = pd.read_table(path[option]['weather'].format(day.date()), header=None,\n",
    "                      names=['time', 'weather', 'temprature', 'pm2.5'])\n",
    "    df['time'] = Time(df, day.date())\n",
    "    df = df.drop_duplicates(subset='time')\n",
    "    DF = pd.DataFrame({'time': T_range}, columns=df.columns)\n",
    "    DF = DF.set_index('time')\n",
    "    DF.update(df.set_index('time'))\n",
    "    return DF.fillna(method='bfill').fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Dictionary of order data for testing, indexed by date, cols = [gap]\n",
    "test_order = {} \n",
    "# Dictionary of traffic data for testing, indexed by date, cols = [weekday, district, time, LV1, LV2, LV3, LV4]\n",
    "test_traffic = {}\n",
    "# Dictionary of weather data for testing, indexed by date, cols = [temperature, weather, pm2.5]\n",
    "test_weather = {} \n",
    "for day in pd.date_range('1/23/2016', periods=5, freq='2D'):\n",
    "    test_order[str(day.date())] = DTG(day, 'test')\n",
    "    test_traffic[str(day.date())] = Traffic(day, 'test')\n",
    "    test_weather[str(day.date())] = Weather(day, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Check data\n",
    "print len(test_order.keys()) == 5\n",
    "print len(test_traffic.keys()) == 5\n",
    "print len(test_weather.keys()) == 5\n",
    "print all(test_order['2016-01-23'].columns.values == np.array(['gap']))\n",
    "print all(test_traffic['2016-01-23'].columns.values == np.array(['LV1', 'LV2', 'LV3', 'LV4', 'day', 'district', 'time', 'weekday']))\n",
    "print all(test_weather['2016-01-23'].columns.values == np.array(['weather', 'temprature', 'pm2.5']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Dictionary of order data for training, indexed by date, cols = [gap]\n",
    "train_order = {}\n",
    "# Dictionary of traffic data for training, indexed by date, cols = [weekday, district, time, LV1, LV2, LV3, LV4]\n",
    "train_traffic = {}\n",
    "# Dictionary of weather data for training, indexed by date, cols = [temperature, weather, pm2.5]\n",
    "train_weather = {}\n",
    "for day in pd.date_range('1/1/2016', periods=21, freq='D'):\n",
    "    train_order[str(day.date())] = DTG(day, 'train')\n",
    "    train_traffic[str(day.date())] = Traffic(day, 'train')\n",
    "    train_weather[str(day.date())] = Weather(day, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Check data\n",
    "print len(train_order.keys()) == 21\n",
    "print len(train_traffic.keys()) == 21\n",
    "print len(train_weather.keys()) == 21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# columns = ['district'] + range(1,26)\n",
    "# POI = pd.DataFrame(columns=columns)\n",
    "# with open(path['train']['poi'], 'r') as f:\n",
    "#     for i, line in enumerate(f): \n",
    "#         interests = line.strip().split('\\t')\n",
    "#         row = {'district': interests[0]}\n",
    "#         for item in interests[1:]:\n",
    "#             category,num = item.split(':')\n",
    "#             category = int(category.split('#')[0])\n",
    "#             if category in row:\n",
    "#                 row[category] += int(num)\n",
    "#             else:\n",
    "#                 row[category] = int(num)\n",
    "#         POI = pd.concat( [POI, pd.DataFrame(row, index=[i], columns=columns)])\n",
    "# POI['district'] = District(POI)\n",
    "# POI = POI.set_index('district').sort_index()\n",
    "# POI = POI.fillna(0)\n",
    "# # Standardization\n",
    "# POI = (POI - POI.mean()) / POI.std()\n",
    "# POI.to_csv('./POI.csv', columns=POI.columns, header=True)\n",
    "\n",
    "POI = pd.read_csv('./POI.csv', index_col='district')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore which district is the best for replacing district 54"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Mergin weather and gap data each day, and store it in a single csv\n",
    "# def preprocessing1(day):\n",
    "#     X = train_order[day].reindex(index(D_range,T_range)).fillna(0)\n",
    "#     X['last'] = X['gap'].shift().fillna(method='bfill')\n",
    "#     X['last2'] = X['gap'].shift(2).fillna(method='bfill') \n",
    "#     X['GAP'] = pd.Series(index=X.index)\n",
    "#     X['time'] = pd.Series(index=X.index)\n",
    "#     X['district'] = pd.Series(index=X.index)\n",
    "#     for D in D_range:\n",
    "#         X.loc[(D, T_range), 'GAP'] = X.loc[(D, T_range),'gap'].shift(-1).fillna(method='ffill')\n",
    "#         X.loc[(D, T_range), 'time'] = pd.DataFrame(T_range, columns=['time'],index=index(D, T_range))\n",
    "#         X.loc[(D, T_range), 'district'] = pd.DataFrame([D]*144, columns=['district'],index=index(D, T_range))\n",
    "#     X = X.join(train_weather[day], on='time')\n",
    "#     Y_gap = X['GAP']\n",
    "#     X.drop('GAP', axis=1, inplace=True)\n",
    "#     return X, Y_gap\n",
    "\n",
    "# for d in pd.date_range('1/2/2016', periods=20, freq='D'):\n",
    "#     X, Y_gap = preprocessing1(str(d.date()))\n",
    "    \n",
    "#     X = X.join(POI,on='district')\n",
    "#     X.sort_index(inplace=True)\n",
    "    \n",
    "#     Y_gap.sort_index(inplace=True)\n",
    "#     X.to_csv('./X/{}.csv'.format(str(d.date())), columns=X.columns, header=True)\n",
    "#     Y_gap.to_csv('./Y_gap/{}.csv'.format(str(d.date())), header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced by disctric 17 : 0.98912147\n",
      "Replaced by disctric 18 : 0.98698988\n",
      "Replaced by disctric 19 : 0.77650698\n",
      "Replaced by disctric 20 : 0.72371558\n",
      "Replaced by disctric 21 : 0.90578814\n",
      "Replaced by disctric 22 : 0.85776423\n",
      "Replaced by disctric 23 : 3.11777664\n",
      "Replaced by disctric 24 : 0.59887103\n",
      "Replaced by disctric 25 : 0.74924907\n",
      "Replaced by disctric 26 : 0.98615067\n",
      "Replaced by disctric 27 : 0.80867298\n",
      "Replaced by disctric 28 : 0.61996468\n",
      "Replaced by disctric 29 : 0.85480506\n",
      "Replaced by disctric 30 : 0.98992951\n",
      "Replaced by disctric 31 : 0.97505635\n",
      "Replaced by disctric 32 : 1.00273342\n",
      "Replaced by disctric 33 : 0.99017887\n",
      "Replaced by disctric 34 : 0.98325421\n",
      "Replaced by disctric 35 : 0.99271328\n",
      "Replaced by disctric 36 : 0.99436532\n",
      "Replaced by disctric 37 : 1.04983252\n",
      "Replaced by disctric 38 : 0.97790965\n",
      "Replaced by disctric 39 : 0.99463147\n",
      "Replaced by disctric 40 : 0.99509663\n",
      "Replaced by disctric 41 : 0.98831103\n",
      "Replaced by disctric 42 : 0.74919821\n",
      "Replaced by disctric 43 : 0.99647533\n",
      "Replaced by disctric 44 : 0.99103486\n",
      "Replaced by disctric 45 : 0.98905673\n",
      "Replaced by disctric 46 : 0.90203604\n",
      "Replaced by disctric 47 : 0.97719033\n",
      "Replaced by disctric 48 : 1.65585771\n",
      "Replaced by disctric 49 : 0.99523330\n",
      "Replaced by disctric 50 : 0.99402964\n",
      "Replaced by disctric 51 : 3.39464397\n",
      "Replaced by disctric 52 : 0.99622356\n",
      "Replaced by disctric 53 : 0.99042104\n",
      "Replaced by disctric 55 : 0.99966432\n",
      "Replaced by disctric 56 : 0.99899295\n",
      "Replaced by disctric 57 : 0.98358989\n",
      "Replaced by disctric 58 : 0.99629550\n",
      "Replaced by disctric 59 : 0.99899295\n",
      "Replaced by disctric 60 : 0.99699324\n",
      "Replaced by disctric 61 : 0.99699324\n",
      "Replaced by disctric 62 : 1.00290126\n",
      "Replaced by disctric 63 : 0.99707956\n",
      "Replaced by disctric 64 : 0.99622356\n",
      "Replaced by disctric 65 : 0.99874119\n",
      "Replaced by disctric 66 : 0.99471299\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "# from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# without54 = range(1,67)\n",
    "# without54.remove(54)\n",
    "# def preprocessing2(day, Mask):\n",
    "#     # filling traffic of district 54 with other district    \n",
    "#     traffic_rest = train_traffic[day].reindex(index(without54, T_range)).fillna(method='bfill')\n",
    "#     mask = Mask # The district replace district 54\n",
    "#     traffic_54 = pd.DataFrame(traffic_rest.loc[index(mask, T_range)].values, \n",
    "#                               index=index(54, T_range), columns=traffic_rest.columns)\n",
    "#     return traffic_rest, traffic_54\n",
    "\n",
    "\n",
    "# for D in without54:\n",
    "#     X_rest = []\n",
    "#     Y_gap_rest = []\n",
    "#     X_54 = []\n",
    "#     Y_gap_54 = []\n",
    "#     for d in pd.date_range('1/2/2016', periods=20, freq='D'):\n",
    "#         X_all = pd.read_csv('./X/{}.csv'.format(str(d.date())), index_col=('district', 'time'))\n",
    "#         Y_gap_all = pd.read_csv('./Y_gap/{}.csv'.format(str(d.date())), index_col=('district', 'time'))\n",
    "#         traffic_rest, traffic_54 = preprocessing2(str(d.date()), D)\n",
    "#         tempX_rest = pd.concat([X_all.loc[(without54, T_range),:], traffic_rest], axis=1)\n",
    "#         tempX_54 = pd.concat([X_all.loc[(54, T_range),:], traffic_54],axis=1)\n",
    "#         tempX_rest = tempX_rest.drop(['time.1','district.1'],1)\n",
    "#         tempX_54 = tempX_54.drop(['time.1','district.1'],1)\n",
    "#         X_rest.append(tempX_rest)\n",
    "#         X_54.append(tempX_54)\n",
    "#         Y_gap_rest.append(Y_gap_all.loc[(without54, T_range),:])\n",
    "#         Y_gap_54.append(Y_gap_all.loc[(54, T_range),:])\n",
    "#     X_rest = pd.concat(X_rest)\n",
    "#     X_rest.sort_index(inplace=True)\n",
    "#     X_54 = pd.concat(X_54)\n",
    "#     X_54.sort_index(inplace=True)\n",
    "#     Y_gap_rest = pd.concat(Y_gap_rest)\n",
    "#     Y_gap_rest.sort_index(inplace=True)\n",
    "#     Y_gap_54 = pd.concat(Y_gap_54)\n",
    "#     Y_gap_54.sort_index(inplace=True)\n",
    "\n",
    "\n",
    "#     Y_gap_rest[Y_gap_rest>10]=11\n",
    "#     Y_gap_54[Y_gap_54>10]=11\n",
    "#     columns = ['gap', 'last', 'last2', 'LV1', 'LV2', 'LV3', 'LV4', 'district', 'time', 'pm2.5']\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X_rest[columns], Y_gap_rest, test_size=0.7)\n",
    "\n",
    "#     params = {'loss': 'deviance', 'learning_rate': 0.15, 'n_estimators': 20, 'min_samples_leaf':10, 'min_samples_split':100,\n",
    "#               'max_depth': 3, 'max_features': 0.8, 'subsample': 1.0, 'min_samples_split': 20, 'random_state':1,\n",
    "#               'verbose':0}\n",
    "#     grd = GradientBoostingClassifier(**params)\n",
    "#     grd.fit(X_train,y_train['GAP'])\n",
    "    \n",
    "#     testX = X_54[Y_gap_54['GAP']>0][columns]\n",
    "#     testY = Y_gap_54[Y_gap_54['GAP']>0]['GAP']\n",
    "#     print \"Replaced by disctric {} : {:.8f}\".format(D,((testY - grd.predict(testX)).abs() / testY).sum() / testY.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Replaced by disctric 17 : 0.98912147\n",
    "# Replaced by disctric 18 : 0.98698988\n",
    "# Replaced by disctric 19 : 0.77650698\n",
    "# Replaced by disctric 20 : 0.72371558  -> 3rd\n",
    "# Replaced by disctric 21 : 0.90578814\n",
    "# Replaced by disctric 22 : 0.85776423\n",
    "# Replaced by disctric 23 : 3.11777664\n",
    "# Replaced by disctric 24 : 0.59887103  -> 1st\n",
    "# Replaced by disctric 25 : 0.74924907   \n",
    "# Replaced by disctric 26 : 0.98615067\n",
    "# Replaced by disctric 27 : 0.80867298\n",
    "# Replaced by disctric 28 : 0.61996468  -> 2nd\n",
    "# Replaced by disctric 29 : 0.85480506\n",
    "# Replaced by disctric 30 : 0.98992951\n",
    "# Replaced by disctric 31 : 0.97505635\n",
    "# Replaced by disctric 32 : 1.00273342\n",
    "# Replaced by disctric 33 : 0.99017887\n",
    "# Replaced by disctric 34 : 0.98325421\n",
    "# Replaced by disctric 35 : 0.99271328\n",
    "# Replaced by disctric 36 : 0.99436532\n",
    "# Replaced by disctric 37 : 1.04983252\n",
    "# Replaced by disctric 38 : 0.97790965\n",
    "# Replaced by disctric 39 : 0.99463147\n",
    "# Replaced by disctric 40 : 0.99509663\n",
    "# Replaced by disctric 41 : 0.98831103\n",
    "# Replaced by disctric 42 : 0.74919821\n",
    "# Replaced by disctric 43 : 0.99647533\n",
    "# Replaced by disctric 44 : 0.99103486\n",
    "# Replaced by disctric 45 : 0.98905673\n",
    "# Replaced by disctric 46 : 0.90203604\n",
    "# Replaced by disctric 47 : 0.97719033\n",
    "# Replaced by disctric 48 : 1.65585771\n",
    "# Replaced by disctric 49 : 0.99523330\n",
    "# Replaced by disctric 50 : 0.99402964\n",
    "# Replaced by disctric 51 : 3.39464397\n",
    "# Replaced by disctric 52 : 0.99622356\n",
    "# Replaced by disctric 53 : 0.99042104\n",
    "# Replaced by disctric 55 : 0.99966432\n",
    "# Replaced by disctric 56 : 0.99899295\n",
    "# Replaced by disctric 57 : 0.98358989\n",
    "# Replaced by disctric 58 : 0.99629550\n",
    "# Replaced by disctric 59 : 0.99899295\n",
    "# Replaced by disctric 60 : 0.99699324\n",
    "# Replaced by disctric 61 : 0.99699324\n",
    "# Replaced by disctric 62 : 1.00290126\n",
    "# Replaced by disctric 63 : 0.99707956\n",
    "# Replaced by disctric 64 : 0.99622356\n",
    "# Replaced by disctric 65 : 0.99874119\n",
    "# Replaced by disctric 66 : 0.99471299"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing training data X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Filling traffic of district 54 with other district\n",
    "def replace54(day, mask):\n",
    "    traffic_rest = train_traffic[day].reindex(index(without54, T_range)).fillna(method='bfill')\n",
    "    traffic_54 = pd.DataFrame(traffic_rest.loc[index(mask, T_range)].values, \n",
    "                              index=index(54, T_range), columns=traffic_rest.columns)\n",
    "    return traffic_rest, traffic_54\n",
    "\n",
    "Mask = 24 # Mask is the district replacing district 54\n",
    "without54 = range(1,67)\n",
    "without54.remove(54)\n",
    "X = []\n",
    "Y = []\n",
    "for d in pd.date_range('1/2/2016', periods=20, freq='D'):\n",
    "    X_all = pd.read_csv('./X/{}.csv'.format(str(d.date())), index_col=('district', 'time'))\n",
    "    Y_all = pd.read_csv('./Y_gap/{}.csv'.format(str(d.date())), index_col=('district', 'time'))\n",
    "    traffic_rest, traffic_54 = replace54(str(d.date()), Mask)\n",
    "    \n",
    "    tempX_rest = pd.concat([X_all.loc[(without54, T_range),:], traffic_rest], axis=1)\n",
    "    tempX_rest = tempX_rest.drop(['time.1','district.1'],1)\n",
    "    tempX_54 = pd.concat([X_all.loc[(54, T_range),:], traffic_54],axis=1)    \n",
    "    tempX_54 = tempX_54.drop(['time.1','district.1'],1)    \n",
    "    tempX_all = pd.concat([tempX_rest, tempX_54]).sort_index()\n",
    "    X.append(tempX_all)\n",
    "\n",
    "    tempY_rest = Y_all.loc[(without54, T_range),:]\n",
    "    tempY_54 = Y_all.loc[(54, T_range),:]\n",
    "    tempY_all = pd.concat([tempY_rest, tempY_54]).sort_index()\n",
    "    Y.append(tempY_all)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = pd.concat(X)\n",
    "Y = pd.concat(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print len(X.columns) == 39\n",
    "print Y.shape[0] == X.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Developing Zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def add_test_data(day):\n",
    "    X = train_order[day]\n",
    "    X['diff'] = pd.Series(index=X.index)\n",
    "    for D in D_range:\n",
    "        X.loc[(D, T_range),'diff'] = X.loc[(D, T_range),'gap'].diff().shift(-1).fillna(0)\n",
    "    # filling nearest value for missin traffic data \n",
    "    tempX = train_traffic[day].reindex(index(D_range,T_range)).fillna(method='bfill').fillna(method='ffill')\n",
    "    X = pd.concat([X, tempX],axis=1)\n",
    "    X = X.join(train_weather[day], on='time')\n",
    "    Y = X['diff']\n",
    "    X.drop('diff', axis=1, inplace=True)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identified the most common gap growth each day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# DF = pd.DataFrame(columns=range(1,12))\n",
    "# for d in pd.date_range('1/2/2016', periods=20, freq='1D'):\n",
    "#     df = train_order[str(d.date())]\n",
    "#     df = df.reindex(index(D_range, T_range)).fillna(0)\n",
    "#     for D in D_range:\n",
    "#         df.loc[(D, T_range),'diff'] = df.loc[(D, T_range),'gap'].diff().shift(-1).fillna(0)\n",
    "#     row = pd.DataFrame(df['diff'].value_counts().sort_values(ascending=False).iloc[:11].index.values.reshape((1,11)),\n",
    "#                        columns=range(1,12), index=[d.day])\n",
    "#     DF = DF.append(row)\n",
    "# print DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identified the most common gap each day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# DF = pd.DataFrame(columns=range(1,12))\n",
    "# for d in pd.date_range('1/2/2016', periods=20, freq='1D'):\n",
    "#     df = train_order[str(d.date())]\n",
    "#     row = pd.DataFrame(df['gap'].value_counts().sort_values(ascending=False)[:11].index.values.reshape((1,11)),\n",
    "#                        columns=range(1,12), index=[d.day])\n",
    "#     DF = DF.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for d in pd.date_range('1/23/2016', periods=5, freq='2D'):\n",
    "#     df = test_order[str(d.date())]\n",
    "#     row = pd.DataFrame(df['gap'].value_counts().sort_values(ascending=False)[:11].index.values.reshape((1,11)),\n",
    "#                        columns=range(1,12), index=[d.day])\n",
    "#     DF = DF.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# columns is the top 11 most common gap\n",
    "# index is each day\n",
    "# print DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method4 by GradientBoosting on classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def score_GBD(day, pred):\n",
    "    ans = test_order[day].reindex(index(D_range, S_range[day])).fillna(0)\n",
    "    ans = ans['gap'].values\n",
    "    pred = pred[ans>0]\n",
    "    ans = ans[ans>0]\n",
    "    gap = (ans - pred) / ans\n",
    "    return np.fabs(gap).sum()/ans.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def score_on_test_data(clf, columns):\n",
    "#     SLOT1 = range(44,152,12)\n",
    "#     SLOT2 = range(56,152,12)\n",
    "#     RANGE = {'2016-01-23': SLOT1, '2016-01-25': SLOT2, '2016-01-27': SLOT1, '2016-01-29': SLOT2, '2016-01-31': SLOT1}\n",
    "#     scores = []\n",
    "#     for day in RANGE.keys():\n",
    "#         x = select_last_points(day, RANGE[day])\n",
    "#         score = score3(day, clf.predict(x[columns]))\n",
    "#         scores.append(score * x.shape[0])\n",
    "#         print '\\t score: {}'.format(score)\n",
    "#     print np.array(scores).sum()/2838"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def select_last_points(day, slot):\n",
    "    slot = np.array(slot)\n",
    "    x = test_order[day].reindex(index(D_range, slot)).fillna(0)\n",
    "    x['last'] = test_order[day].reindex(index(D_range, slot-1)).fillna(0)\n",
    "    x = pd.concat([x, test_traffic[day].reindex(index(D_range, slot))],axis=1)\n",
    "#     # For missing traffic data on district 54, replaced by Mask\n",
    "    for t in slot:\n",
    "        x.loc[(54,t)]['LV1':'weekday'] = x.loc[(Mask,t)]['LV1':'weekday']\n",
    "    x = x.join(test_weather[day], on='time')\n",
    "    x = x.join(POI,on='district')\n",
    "    print \"Select data from {} on {}\".format(day, slot)\n",
    "    print \"\\t shape: {}\".format(x.shape)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newY = Y.copy()\n",
    "newX = X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "newX = newX[newY['GAP']>0]\n",
    "newY = newY[newY['GAP']>0]\n",
    "newY[newY['GAP']>12]=13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "columns = ['gap', 'last', 'LV1', 'LV2', 'LV3', 'LV4', 'district', 'time', 'pm2.5']\n",
    "X_train, X_test, y_train, y_test = train_test_split(newX[columns], newY['GAP'], test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1      152012.0977            3.53m\n",
      "         2      143177.8942            3.33m\n",
      "         3      136917.5868            3.26m\n",
      "         4      132190.8600            3.65m\n",
      "         5      128448.1977            3.52m\n",
      "         6      125453.5681            3.42m\n",
      "         7      123012.2817            3.33m\n",
      "         8      120990.2951            3.21m\n",
      "         9      119327.0906            3.09m\n",
      "        10      117932.8796            3.02m\n",
      "        20      111431.4968            2.23m"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "params = {'loss': 'deviance', 'learning_rate': 0.1, 'n_estimators': 50, 'min_samples_leaf':10, 'min_samples_split':100,\n",
    "          'max_depth': 3, 'max_features': 0.8, 'subsample': 1.0, 'min_samples_split': 20, 'random_state':1,\n",
    "          'verbose':1}\n",
    "grd = GradientBoostingClassifier(**params)\n",
    "grd.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select data from 2016-01-31 on [ 44  56  68  80  92 104 116 128 140]\n",
      "\t shape: (594, 38)\n",
      "\t score: 0.48586583534\n",
      "Select data from 2016-01-23 on [ 44  56  68  80  92 104 116 128 140]\n",
      "\t shape: (594, 38)\n",
      "\t score: 0.455204963845\n",
      "Select data from 2016-01-29 on [ 56  68  80  92 104 116 128 140]\n",
      "\t shape: (528, 38)\n",
      "\t score: 0.525009465729\n",
      "Select data from 2016-01-27 on [ 44  56  68  80  92 104 116 128 140]\n",
      "\t shape: (594, 38)\n",
      "\t score: 0.49087959706\n",
      "Select data from 2016-01-25 on [ 56  68  80  92 104 116 128 140]\n",
      "\t shape: (528, 38)\n",
      "\t score: 0.54472881014\n",
      "0.498731622632\n"
     ]
    }
   ],
   "source": [
    "SLOT1 = range(44,152,12)\n",
    "SLOT2 = range(56,152,12)\n",
    "RANGE = {'2016-01-23': SLOT1, '2016-01-25': SLOT2, '2016-01-27': SLOT1, '2016-01-29': SLOT2, '2016-01-31': SLOT1}\n",
    "scores = []\n",
    "for day in RANGE.keys():\n",
    "    x = select_last_points(day, RANGE[day])\n",
    "    y_pred = grd.predict(x[columns])\n",
    "    score = score_GBD(day, y_pred)\n",
    "    scores.append(score * x.shape[0])\n",
    "    print '\\t score: {}'.format(score)\n",
    "print np.array(scores).sum()/2838"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = {'loss': 'deviance', 'learning_rate': 0.1, 'n_estimators': 50, 'min_samples_leaf':10, 'min_samples_split':100,\n",
    "          'max_depth': 3, 'max_features': 0.8, 'subsample': 1.0, 'min_samples_split': 20, 'random_state':1}\n",
    "clf = GradientBoostingClassifier(**params)\n",
    "clf.fit(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select important columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columns = []\n",
    "for i, important in enumerate(clf.feature_importances_ > 0.02):\n",
    "    if important:\n",
    "        columns.append(X.columns[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = {'loss': 'deviance', 'learning_rate': 0.15, 'n_estimators': 50, 'min_samples_leaf':10, 'min_samples_split':100,\n",
    "          'max_depth': 3, 'max_features': 0.8, 'subsample': 1.0, 'min_samples_split': 20, 'random_state':1,\n",
    "          'verbose':1}\n",
    "clf = GradientBoostingClassifier(**params)\n",
    "clf.fit(X[columns],Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# learning rate: 0.1 -> 0.05 : 0.498091376721 -> 0.50989613439\n",
    "# learning rate: 0.1 -> 0.15 : 0.498091376721 -> 0.50989613439\n",
    "get_score(clf, columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing ANS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write4(x, day, slot, clf, mode):\n",
    "    with open('ans4_v1.csv', mode) as f:\n",
    "        writer = csv.writer(f, delimiter=',')\n",
    "        for D in D_range:\n",
    "            for S in slot:\n",
    "                if D is 54:\n",
    "                    df = test_order[day].reindex(index(D_range,T_range)).fillna(0)['gap']\n",
    "                    gap = 0.5 * df.loc[(D, S)] + 0.3 * df.loc[(D, S-1)] + 0.2 * df.loc[(D, S-2)]\n",
    "                else:\n",
    "                    gap = clf.predict(x.loc[(D,S)].reshape(1, -1))[0]\n",
    "                gap = 0 if gap < 0 else gap\n",
    "                writer.writerow([str(D),'{}-{}'.format(day,S+1), '{:.15f}'.format(gap)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SLOT1 = range(45,153,12)\n",
    "SLOT2 = range(57,153,12)\n",
    "RANGE = {'2016-01-23': SLOT1, '2016-01-25': SLOT2, '2016-01-27': SLOT1, '2016-01-29': SLOT2, '2016-01-31': SLOT1}\n",
    "scores = []\n",
    "for day in RANGE.keys():\n",
    "    x = select_last_points(day, RANGE[day])\n",
    "    write4(x[columns], day, S_range[day], clf, 'a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature transformations with ensembles of trees (cont.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score5(day, pred):\n",
    "    Ds = range(1,67)\n",
    "    Ds.reomve(54)\n",
    "    ans = test_order[day].reindex(index(D_range, S_range[day])).fillna(0)\n",
    "    ans = ans['gap'].values\n",
    "    pred = pred[ans>0]\n",
    "    ans = ans[ans>0]\n",
    "    gap = (ans - pred) / ans\n",
    "    # For district 54\n",
    "    another = test_order[day].reindex(index(54, S_range[day])).fillna(0)\n",
    "    \n",
    "    return np.fabs(gap).sum()/ans.shape[0]\n",
    "\n",
    "def get_score(clf, columns):\n",
    "    SLOT1 = range(44,152,12)\n",
    "    SLOT2 = range(56,152,12)\n",
    "    RANGE = {'2016-01-23': SLOT1, '2016-01-25': SLOT2, '2016-01-27': SLOT1, '2016-01-29': SLOT2, '2016-01-31': SLOT1}\n",
    "    scores = []\n",
    "    for day in RANGE.keys():\n",
    "        x = select_last_points(day, RANGE[day])\n",
    "        score = score5(day, clf.predict(x[columns].dropna()))\n",
    "        scores.append(score * x.shape[0])\n",
    "        print '\\t score: {}'.format(score)\n",
    "    print np.array(scores).sum()/2838"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = Y_gap[Y_gap>0]\n",
    "X = X[Y_gap>0]\n",
    "Y[Y>12]=13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# columns = ['gap', 'last', 'LV1', 'LV2', 'LV3', 'LV4', 'district', 'time', 'pm2.5']\n",
    "new_columns = columns + ['last2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_train_lr, y_train, y_train_lr = train_test_split(X[columns], Y, test_size=0.7)\n",
    "\n",
    "params = {'loss': 'deviance', 'learning_rate': 0.15, 'n_estimators': 50, 'min_samples_leaf':10, 'min_samples_split':100,\n",
    "          'max_depth': 3, 'max_features': 0.8, 'subsample': 1.0, 'min_samples_split': 20, 'random_state':1,\n",
    "          'verbose':1}\n",
    "grd = GradientBoostingClassifier(**params)\n",
    "grd.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = select_last_points(day, RANGE['2016-01-23'])\n",
    "print x[columns].loc[(54,RANGE['2016-01-23']),:]\n",
    "#print get_score(grd, columns)\n",
    "# print ((y_train_lr - grd.predict(X_train_lr)).abs() / y_train_lr).sum() / (66*y_train_lr.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "enc = OneHotEncoder()\n",
    "lm_params = {'class_weight':{1:16,2:14,3:12,4:10,5:8}, 'solver':'newton-cg', 'random_state':1,\n",
    "             'penalty':'l2'}\n",
    "lm = LogisticRegression(**lm_params)\n",
    "enc.fit(grd.apply(X_train)[:, :, 0])\n",
    "lm.fit(enc.transform(grd.apply(X_train_lr)[:, :, 0]), y_train_lr)\n",
    "# lm.fit(X_train_lr, y_train_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SLOT1 = range(44,152,12)\n",
    "SLOT2 = range(56,152,12)\n",
    "RANGE = {'2016-01-23': SLOT1, '2016-01-25': SLOT2, '2016-01-27': SLOT1, '2016-01-29': SLOT2, '2016-01-31': SLOT1}\n",
    "scores = []\n",
    "for day in RANGE.keys():\n",
    "    x = select_last_points(day, RANGE[day])\n",
    "    y_pred_grd_lm = lm.predict_proba(enc.transform(grd.apply(x[columns])[:, :, 0]))[:, 1]\n",
    "    score = score3(day, pd.Series(y_pred_grd_lm, index=x.index))\n",
    "    scores.append(score * x.shape[0])\n",
    "    print '\\t score: {}'.format(score)\n",
    "print np.array(scores).sum()/2838"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SLOT1 = range(44,152,12)\n",
    "SLOT2 = range(56,152,12)\n",
    "RANGE = {'2016-01-23': SLOT1, '2016-01-25': SLOT2, '2016-01-27': SLOT1, '2016-01-29': SLOT2, '2016-01-31': SLOT1}\n",
    "ans = pd.DataFrame()\n",
    "scores = pd.DataFrame()\n",
    "for day in RANGE.keys():\n",
    "    x = select_last_points(day, RANGE[day])\n",
    "    y_pred_grd_lm = lm.predict_proba(enc.transform(grd.apply(x[columns])[:, :, 0]))[:, 1]\n",
    "    a, s = score4(day, pd.Series(y_pred_grd_lm, index=x.index))\n",
    "    ans = pd.concat([ans, a], axis=1)\n",
    "    scores = pd.concat([scores, s], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "worst = scores[(scores>=0.8).any(1)]\n",
    "print ans.loc[worst.index]['2016-01-23'].value_counts()[:10]\n",
    "print ans.loc[worst.index]['2016-01-25'].value_counts()[:10]\n",
    "print ans.loc[worst.index]['2016-01-27'].value_counts()[:10]\n",
    "print ans.loc[worst.index]['2016-01-29'].value_counts()[:10]\n",
    "print ans.loc[worst.index]['2016-01-31'].value_counts()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore which gap is the most common errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score4(day, pred):\n",
    "    a = test_order[day].reindex(index(D_range, S_range[day])).fillna(0)\n",
    "    ans = a['gap'].values\n",
    "    pred = pred[ans>0]\n",
    "    ans = ans[ans>0]\n",
    "    gap = (ans - pred) / ans\n",
    "    temp = pd.DataFrame(ans, index=pred.index,columns=[day])\n",
    "    return temp, pd.DataFrame(np.fabs(gap),columns=[day])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SLOT1 = range(44,152,12)\n",
    "SLOT2 = range(56,152,12)\n",
    "RANGE = {'2016-01-23': SLOT1, '2016-01-25': SLOT2, '2016-01-27': SLOT1, '2016-01-29': SLOT2, '2016-01-31': SLOT1}\n",
    "ans = pd.DataFrame()\n",
    "scores = pd.DataFrame()\n",
    "for day in RANGE.keys():\n",
    "    x = select_last_points(day, RANGE[day])\n",
    "    a, s = score4(day, pd.Series(clf.predict(x[columns]), index=x.index))\n",
    "    ans = pd.concat([ans, a], axis=1)\n",
    "    scores = pd.concat([scores, s], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "worst = scores[(scores>=0.8).any(1)]\n",
    "print ans.loc[worst.index]['2016-01-23'].value_counts()[:10]\n",
    "print ans.loc[worst.index]['2016-01-25'].value_counts()[:10]\n",
    "print ans.loc[worst.index]['2016-01-27'].value_counts()[:10]\n",
    "print ans.loc[worst.index]['2016-01-29'].value_counts()[:10]\n",
    "print ans.loc[worst.index]['2016-01-31'].value_counts()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method3 by GradientBoosting on regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "slot1 = range(45,153,12) # Last time slot of test slot for day 23, 27, 31\n",
    "slot2 = range(57,153,12) # Last time slot of test slot for day 25, 29\n",
    "S_range = {'2016-01-23':slot1, '2016-01-25':slot2, '2016-01-27':slot1, '2016-01-29':slot2, '2016-01-31':slot1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write3(x, day, slot, regr, mode):\n",
    "    with open('ans3_v1.csv', mode) as f:\n",
    "        writer = csv.writer(f, delimiter=',')\n",
    "        for D in D_range:\n",
    "            for S in slot:\n",
    "                key = (D,S)\n",
    "                if key in x.index:\n",
    "                    gap = x['gap'].loc[key] + regr.predict(x.loc[key].reshape(1, -1))[0]\n",
    "                else:\n",
    "                    gap = 1\n",
    "                gap = 0 if gap < 0 else gap\n",
    "                writer.writerow([str(D),'{}-{}'.format(day,S+1), '{:.15f}'.format(gap)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ans3_v1.csv\n",
    "# params = {'loss': 'huber', 'alpha': 0.9, 'n_estimators':250, 'max_features':0.5, 'random_state':1,\n",
    "#           'warm_start':False,'max_depth': 3, 'learning_rate': 0.1, 'subsample': 1.0}\n",
    "#-----brand new turing\n",
    "params = {'loss': 'huber', 'alpha': 0.9, 'n_estimators':20, 'max_features':1.0, 'random_state':1,\n",
    "          'warm_start':False,'max_depth': 10, 'learning_rate': 0.25, 'subsample': 0.85,\n",
    "          'min_samples_leaf': 25, 'min_samples_split':100}\n",
    "\n",
    "# Paramters need to be searched\n",
    "parameters = {'n_estimators': np.arange(100,600,150)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Searching best parameters\n",
    "# scoring_function = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "# regr = grid_search.GridSearchCV(GradientBoostingRegressor(**params), \n",
    "#                                 param_grid=parameters, scoring=scoring_function, cv=3)\n",
    "# regr.fit(X, Y)\n",
    "# Regr = regr.best_estimator_\n",
    "\n",
    "Regr = GradientBoostingRegressor(**params)\n",
    "Regr.fit(X, Y)\n",
    "print Regr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# max_features: sqrt -> 0.5 : 0.538287 -> 0.528706599387\n",
    "# max_features: 0.5 -> 0.8 : 0.528706599387 -> 0.530272920336\n",
    "#-----brand new turing\n",
    "# alpha: 0.9 -> 0.6 : 0.537699383041 -> 0.576867122284\n",
    "# learning_rate: 0.2 : 0.536744595218\n",
    "SLOT1 = range(44,152,12)\n",
    "SLOT2 = range(56,152,12)\n",
    "RANGE = {'2016-01-23': SLOT1, '2016-01-25': SLOT2, '2016-01-27': SLOT1, '2016-01-29': SLOT2, '2016-01-31': SLOT1}\n",
    "scores = []\n",
    "for day in RANGE.keys():\n",
    "    x = select_last_points(day, RANGE[day])\n",
    "    score = score3(day, x['gap']+Regr.predict(x))\n",
    "    scores.append(score * x.shape[0])\n",
    "    print '\\t score: {}'.format(score)\n",
    "print np.array(scores).sum()/2838"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing ANS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SLOT1 = range(45,153,12)\n",
    "SLOT2 = range(57,153,12)\n",
    "RANGE = {'2016-01-23': SLOT1, '2016-01-25': SLOT2, '2016-01-27': SLOT1, '2016-01-29': SLOT2, '2016-01-31': SLOT1}\n",
    "scores = []\n",
    "for day in RANGE.keys():\n",
    "    x = select_last_points(day, RANGE[day])\n",
    "    write3(x, day, S_range[day], Regr, 'a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Method 2 by using interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "slot1 = range(45,153,12)\n",
    "slot2 = range(57,153,12)\n",
    "S_range = {'2016-01-22':slot1, '2016-01-24':slot2, '2016-01-26':slot1, '2016-01-28':slot2, '2016-01-30':slot1}\n",
    "D_range = range(1,67)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Day_range = {'2016-01-22':pd.date_range('1/2/2016', periods=3, freq='7D'),\n",
    "             '2016-01-24':pd.date_range('1/3/2016', periods=3, freq='7D'),\n",
    "             '2016-01-26':pd.date_range('1/5/2016', periods=3, freq='7D'),\n",
    "             '2016-01-28':pd.date_range('1/7/2016', periods=3, freq='7D'),\n",
    "             '2016-01-30':pd.date_range('1/9/2016', periods=2, freq='7D')}\n",
    "def naive_score2(day):\n",
    "    ans = test_order[day].select(lambda x: x[1] in S_range[day])\n",
    "    \n",
    "    \n",
    "    deltas = []\n",
    "    for d in Day_range[day]:\n",
    "        data = train_order[str(d.date())].reindex([x for x in itertools.product(D_range,range(1,145))]).fillna(0)\n",
    "        data = data.diff().shift(-1)\n",
    "        data = data.loc[ans.index]\n",
    "        deltas.append(data)\n",
    "\n",
    "    delta = deltas[0]\n",
    "    for i in range(1,len(deltas)):\n",
    "        delta.add(deltas[i], fill_value=0)\n",
    "    pred = test_order[day].shift().loc[ans.index].fillna(0)+(delta/len(deltas))\n",
    "    gap = (ans - pred) / ans\n",
    "\n",
    "    return gap.abs().sum()/(66*len(S_range[day]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print naive_score2('2016-01-22')\n",
    "print naive_score2('2016-01-24')\n",
    "print naive_score2('2016-01-26')\n",
    "print naive_score2('2016-01-28')\n",
    "print naive_score2('2016-01-30')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def slope(day):\n",
    "    base_points = test_order[day].select(lambda x: x[1] in S_range[day])\n",
    "    deltas = []\n",
    "    for d in Day_range[day]:\n",
    "        data = train_order[str(d.date())].reindex([x for x in itertools.product(D_range,range(1,145))]).fillna(0)\n",
    "        data = data.diff().shift(-1)\n",
    "        deltas.append(data)\n",
    "    delta = deltas[0]\n",
    "    for i in range(1,len(deltas)):\n",
    "        delta = delta + deltas[i]\n",
    "    return base_points, delta/len(deltas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write2(day, base_points, slot, delta, mode):\n",
    "    with open('ans.csv', mode) as f:\n",
    "        writer = csv.writer(f, delimiter=',')\n",
    "        for D in range(1,67):\n",
    "            for S in slot:\n",
    "                key = (D,S-1)\n",
    "                if key in base_points.index:\n",
    "                    gap = base_points['gap'].loc[key] + delta['gap'].loc[key]\n",
    "                    gap = base_points['gap'].loc[key] if gap < 0 else gap\n",
    "                else:\n",
    "                    gap = 0.0\n",
    "                writer.writerow([D,'{}-{}'.format(day,S), '{:.3f}'.format(gap)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Day22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "day = '2016-01-22'\n",
    "base_points, delta = slope(day)\n",
    "write2(day, base_points, test_slot1, delta, 'w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Day24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "day = '2016-01-24'\n",
    "base_points, delta = slope(day)\n",
    "write2(day, base_points, test_slot2, delta, 'a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Day26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "day = '2016-01-26'\n",
    "base_points, delta = slope(day)\n",
    "write2(day, base_points, test_slot1, delta, 'a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Day28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "day = '2016-01-28'\n",
    "base_points, delta = slope(day)\n",
    "write2(day, base_points, test_slot2, delta, 'a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Day30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "day = '2016-01-30'\n",
    "base_points, delta = slope(day)\n",
    "write2(day, base_points, test_slot1, delta, 'a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict the score of naive method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Day_range = {'2016-01-22':pd.date_range('1/1/2016', periods=3, freq='7D'),\n",
    "             '2016-01-24':pd.date_range('1/3/2016', periods=3, freq='7D'),\n",
    "             '2016-01-26':pd.date_range('1/5/2016', periods=3, freq='7D'),\n",
    "             '2016-01-28':pd.date_range('1/7/2016', periods=3, freq='7D'),\n",
    "             '2016-01-30':pd.date_range('1/9/2016', periods=2, freq='7D')}\n",
    "def naive_score1(day):\n",
    "    ans = test_order[day].select(lambda x: x[1] in S_range[day])\n",
    "    \n",
    "    prediction = []\n",
    "    for d in Day_range[day]:\n",
    "        data = train_order[str(d.date())]\n",
    "        data = data.loc[ans.index].fillna(0)\n",
    "        prediction.append(data)\n",
    "\n",
    "    pred = prediction[0]\n",
    "    for i in range(1,len(prediction)):\n",
    "        pred.add(prediction[i], fill_value=0)\n",
    "    pred = pred/len(prediction)\n",
    "    gap = (ans - pred) / ans\n",
    "\n",
    "    return gap.abs().sum()/(66*len(S_range[day]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print naive_score1('2016-01-22')\n",
    "print naive_score1('2016-01-24')\n",
    "print naive_score1('2016-01-26')\n",
    "print naive_score1('2016-01-28')\n",
    "print naive_score1('2016-01-30')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Method 1 by using mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_slot1 = range(46,154,12)\n",
    "test_slot2 = range(58,154,12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Day22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_day22 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for day in pd.date_range('1/1/2016', periods=3, freq='7D'):\n",
    "    # Read data\n",
    "    order = pd.read_table(path['order'].format(day.date()), header=None, usecols=[1,3,6],\n",
    "                      names=['driver', 'district', 'time'])\n",
    "    # Select NA for calculating the value of gap\n",
    "    order = order[order['driver'].isnull()] \n",
    "    # Translating hash to id\n",
    "    order['district'] = order['district'].apply(lambda x: district[x])\n",
    "    # Translating timestamp to time_id\n",
    "    order['time'] = pd.to_datetime(order['time'])\n",
    "    order['time'] = (order['time'] - day) / M / 10 + 1\n",
    "    order['time'] = order['time'].astype(int)\n",
    "    # Grouping by district and time\n",
    "    test_day22.append(order.groupby(['district', 'time']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('ans.csv', 'w') as f:\n",
    "    writer = csv.writer(f, delimiter=',')\n",
    "    for D in range(1,67):\n",
    "        for S in test_slot1:\n",
    "            key = (D,S)\n",
    "            gap = []\n",
    "            for data in test_day22:\n",
    "                if key in data.groups:\n",
    "                    gap.append(data.get_group(key).shape[0])\n",
    "                else:\n",
    "                    gap.append(0)\n",
    "            writer.writerow([D,'2016-01-22-{}'.format(S), '{:.3f}'.format(np.mean(gap))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Day24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_day24 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for day in pd.date_range('1/3/2016', periods=3, freq='7D'):\n",
    "    # Read data\n",
    "    order = pd.read_table(path['order'].format(day.date()), header=None, usecols=[1,3,6],\n",
    "                      names=['driver', 'district', 'time'])\n",
    "    # Select NA for calculating the value of gap\n",
    "    order = order[order['driver'].isnull()] \n",
    "    # Translating hash to id\n",
    "    order['district'] = order['district'].apply(lambda x: district[x])\n",
    "    # Translating timestamp to time_id\n",
    "    order['time'] = pd.to_datetime(order['time'])\n",
    "    order['time'] = (order['time'] - day) / M / 10 + 1\n",
    "    order['time'] = order['time'].astype(int)\n",
    "    # Grouping by district and time\n",
    "    test_day24.append(order.groupby(['district', 'time']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('ans.csv', 'a') as f:\n",
    "    writer = csv.writer(f, delimiter=',')\n",
    "    for D in range(1,67):\n",
    "        for S in test_slot2:\n",
    "            key = (D,S)\n",
    "            gap = []\n",
    "            for data in test_day24:\n",
    "                if key in data.groups:\n",
    "                    gap.append(data.get_group(key).shape[0])\n",
    "                else:\n",
    "                    gap.append(0)\n",
    "            writer.writerow([D,'2016-01-24-{}'.format(S), '{:.3f}'.format(np.mean(gap))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Day26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_day26 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for day in pd.date_range('1/5/2016', periods=3, freq='7D'):\n",
    "    # Read data\n",
    "    order = pd.read_table(path['order'].format(day.date()), header=None, usecols=[1,3,6],\n",
    "                      names=['driver', 'district', 'time'])\n",
    "    # Select NA for calculating the value of gap\n",
    "    order = order[order['driver'].isnull()] \n",
    "    # Translating hash to id\n",
    "    order['district'] = order['district'].apply(lambda x: district[x])\n",
    "    # Translating timestamp to time_id\n",
    "    order['time'] = pd.to_datetime(order['time'])\n",
    "    order['time'] = (order['time'] - day) / M / 10 + 1\n",
    "    order['time'] = order['time'].astype(int)\n",
    "    # Grouping by district and time\n",
    "    test_day26.append(order.groupby(['district', 'time']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('ans.csv', 'a') as f:\n",
    "    writer = csv.writer(f, delimiter=',')\n",
    "    for D in range(1,67):\n",
    "        for S in test_slot1:\n",
    "            key = (D,S)\n",
    "            gap = []\n",
    "            for data in test_day26:\n",
    "                if key in data.groups:\n",
    "                    gap.append(data.get_group(key).shape[0])\n",
    "                else:\n",
    "                    gap.append(0)\n",
    "            writer.writerow([D,'2016-01-26-{}'.format(S), '{:.3f}'.format(np.mean(gap))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Day28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_day28 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for day in pd.date_range('1/7/2016', periods=3, freq='7D'):\n",
    "    # Read data\n",
    "    order = pd.read_table(path['order'].format(day.date()), header=None, usecols=[1,3,6],\n",
    "                      names=['driver', 'district', 'time'])\n",
    "    # Select NA for calculating the value of gap\n",
    "    order = order[order['driver'].isnull()] \n",
    "    # Translating hash to id\n",
    "    order['district'] = order['district'].apply(lambda x: district[x])\n",
    "    # Translating timestamp to time_id\n",
    "    order['time'] = pd.to_datetime(order['time'])\n",
    "    order['time'] = (order['time'] - day) / M / 10 + 1\n",
    "    order['time'] = order['time'].astype(int)\n",
    "    # Grouping by district and time\n",
    "    test_day28.append(order.groupby(['district', 'time']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('ans.csv', 'a') as f:\n",
    "    writer = csv.writer(f, delimiter=',')\n",
    "    for D in range(1,67):\n",
    "        for S in test_slot2:\n",
    "            key = (D,S)\n",
    "            gap = []\n",
    "            for data in test_day28:\n",
    "                if key in data.groups:\n",
    "                    gap.append(data.get_group(key).shape[0])\n",
    "                else:\n",
    "                    gap.append(0)\n",
    "            writer.writerow([D,'2016-01-28-{}'.format(S), '{:.3f}'.format(np.mean(gap))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Day30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_day30 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for day in pd.date_range('1/9/2016', periods=2, freq='7D'):\n",
    "    # Read data\n",
    "    order = pd.read_table(path['order'].format(day.date()), header=None, usecols=[1,3,6],\n",
    "                      names=['driver', 'district', 'time'])\n",
    "    # Select NA for calculating the value of gap\n",
    "    order = order[order['driver'].isnull()] \n",
    "    # Translating hash to id\n",
    "    order['district'] = order['district'].apply(lambda x: district[x])\n",
    "    # Translating timestamp to time_id\n",
    "    order['time'] = pd.to_datetime(order['time'])\n",
    "    order['time'] = (order['time'] - day) / M / 10 + 1\n",
    "    order['time'] = order['time'].astype(int)\n",
    "    # Grouping by district and time\n",
    "    test_day30.append(order.groupby(['district', 'time']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('ans.csv', 'a') as f:\n",
    "    writer = csv.writer(f, delimiter=',')\n",
    "    for D in range(1,67):\n",
    "        for S in test_slot1:\n",
    "            key = (D,S)\n",
    "            gap = []\n",
    "            for data in test_day30:\n",
    "                if key in data.groups:\n",
    "                    gap.append(data.get_group(key).shape[0])\n",
    "                else:\n",
    "                    gap.append(0)\n",
    "            writer.writerow([D,'2016-01-30-{}'.format(S), '{:.3f}'.format(np.mean(gap))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "day = '2016-01-01'\n",
    "Day = pd.Timestamp(day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "order = pd.read_table(path['order'].format(day), header=None, usecols=[1,3,6],\n",
    "                      names=['driver', 'district_id', 'time'])\n",
    "order = order[order['driver'].isnull()] # Select NA for calculating the value of gap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translating district hash to id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "order['district_id'] = order['district_id'].apply(lambda x: district[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translating timestamp to slot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "order['time'] = pd.to_datetime(order['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "order['time_slot'] = (order['time'] - Day) / M / 10 + 1\n",
    "order['time_slot'] = order['time_slot'].astype(int)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
